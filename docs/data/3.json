{
    "300": {
        "file_id": 22,
        "content": "                    f = to_fraction(value)\n                    p = f * multiplier if f is not None else None\n                    if f is not None and p.denominator == 1:\n                        value = p.numerator\n                    else:\n                        yield output(value)\n                        value = multiplier\n                else:\n                    before = value // 1000 * 1000\n                    residual = value % 1000\n                    value = before + residual * multiplier\n            elif current in self.multipliers_suffixed:\n                multiplier, suffix = self.multipliers_suffixed[current]\n                if value is None:\n                    yield output(str(multiplier) + suffix)\n                elif isinstance(value, str):\n                    f = to_fraction(value)\n                    p = f * multiplier if f is not None else None\n                    if f is not None and p.denominator == 1:\n                        yield output(str(p.numerator) + suffix)\n                    else:",
        "type": "code",
        "location": "/whisper/normalizers/english.py:293-313"
    },
    "301": {
        "file_id": 22,
        "content": "This code is used for normalizing English text by converting numbers and their corresponding units to a specific format. It checks the current unit, applies multipliers if necessary, and handles fractions and suffixes appropriately. The output is yielded as a formatted string.",
        "type": "comment"
    },
    "302": {
        "file_id": 22,
        "content": "                        yield output(value)\n                        yield output(str(multiplier) + suffix)\n                else:  # int\n                    before = value // 1000 * 1000\n                    residual = value % 1000\n                    value = before + residual * multiplier\n                    yield output(str(value) + suffix)\n                value = None\n            elif current in self.preceding_prefixers:\n                # apply prefix (positive, minus, etc.) if it precedes a number\n                if value is not None:\n                    yield output(value)\n                if next in self.words or next_is_numeric:\n                    prefix = self.preceding_prefixers[current]\n                else:\n                    yield output(current)\n            elif current in self.following_prefixers:\n                # apply prefix (dollars, cents, etc.) only after a number\n                if value is not None:\n                    prefix = self.following_prefixers[current]\n                    yield output(value)",
        "type": "code",
        "location": "/whisper/normalizers/english.py:314-335"
    },
    "303": {
        "file_id": 22,
        "content": "This code is responsible for handling the formatting of numbers and appending appropriate suffixes, prefixes or postfixes based on the English language normalization rules. It also takes care of multiplication, preceding and following prefixes application to ensure proper number formatting as per the rules defined in the self.preceding_prefixers and self.following_prefixers dictionaries.",
        "type": "comment"
    },
    "304": {
        "file_id": 22,
        "content": "                else:\n                    yield output(current)\n            elif current in self.suffixers:\n                # apply suffix symbols (percent -> '%')\n                if value is not None:\n                    suffix = self.suffixers[current]\n                    if isinstance(suffix, dict):\n                        if next in suffix:\n                            yield output(str(value) + suffix[next])\n                            skip = True\n                        else:\n                            yield output(value)\n                            yield output(current)\n                    else:\n                        yield output(str(value) + suffix)\n                else:\n                    yield output(current)\n            elif current in self.specials:\n                if next not in self.words and not next_is_numeric:\n                    # apply special handling only if the next word can be numeric\n                    if value is not None:\n                        yield output(value)\n                    yield output(current)",
        "type": "code",
        "location": "/whisper/normalizers/english.py:336-358"
    },
    "305": {
        "file_id": 22,
        "content": "Applies suffix symbols (e.g., percent -> '%'), special handling to words, and yields output based on conditions.",
        "type": "comment"
    },
    "306": {
        "file_id": 22,
        "content": "                elif current == \"and\":\n                    # ignore \"and\" after hundreds, thousands, etc.\n                    if prev not in self.multipliers:\n                        if value is not None:\n                            yield output(value)\n                        yield output(current)\n                elif current == \"double\" or current == \"triple\":\n                    if next in self.ones or next in self.zeros:\n                        repeats = 2 if current == \"double\" else 3\n                        ones = self.ones.get(next, 0)\n                        value = str(value or \"\") + str(ones) * repeats\n                        skip = True\n                    else:\n                        if value is not None:\n                            yield output(value)\n                        yield output(current)\n                elif current == \"point\":\n                    if next in self.decimals or next_is_numeric:\n                        value = str(value or \"\") + \".\"\n                else:\n                    # should all have been covered at this point",
        "type": "code",
        "location": "/whisper/normalizers/english.py:359-379"
    },
    "307": {
        "file_id": 22,
        "content": "This code is responsible for normalizing English text and handles specific conditions such as \"and\", \"double\", \"triple\", and \"point\". It processes the text based on the context of previous and next characters, handles numbers with multipliers, repeats values based on the keyword provided, adds a decimal point when appropriate, and ignores certain keywords if they are not in the correct context.",
        "type": "comment"
    },
    "308": {
        "file_id": 22,
        "content": "                    raise ValueError(f\"Unexpected token: {current}\")\n            else:\n                # all should have been covered at this point\n                raise ValueError(f\"Unexpected token: {current}\")\n        if value is not None:\n            yield output(value)\n    def preprocess(self, s: str):\n        # replace \"<number> and a half\" with \"<number> point five\"\n        results = []\n        segments = re.split(r\"\\band\\s+a\\s+half\\b\", s)\n        for i, segment in enumerate(segments):\n            if len(segment.strip()) == 0:\n                continue\n            if i == len(segments) - 1:\n                results.append(segment)\n            else:\n                results.append(segment)\n                last_word = segment.rsplit(maxsplit=2)[-1]\n                if last_word in self.decimals or last_word in self.multipliers:\n                    results.append(\"point five\")\n                else:\n                    results.append(\"and a half\")\n        s = \" \".join(results)\n        # put a space at number/letter boundary",
        "type": "code",
        "location": "/whisper/normalizers/english.py:380-408"
    },
    "309": {
        "file_id": 22,
        "content": "This code replaces the phrase \"<number> and a half\" with \"<number> point five\" in the given string. It does this by splitting the input string using regular expressions, then rejoining the modified segments with spaces.",
        "type": "comment"
    },
    "310": {
        "file_id": 22,
        "content": "        s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n        s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n        # but remove spaces which could be a suffix\n        s = re.sub(r\"([0-9])\\s+(st|nd|rd|th|s)\\b\", r\"\\1\\2\", s)\n        return s\n    def postprocess(self, s: str):\n        def combine_cents(m: Match):\n            try:\n                currency = m.group(1)\n                integer = m.group(2)\n                cents = int(m.group(3))\n                return f\"{currency}{integer}.{cents:02d}\"\n            except ValueError:\n                return m.string\n        def extract_cents(m: Match):\n            try:\n                return f\"¢{int(m.group(1))}\"\n            except ValueError:\n                return m.string\n        # apply currency postprocessing; \"$2 and ¢7\" -> \"$2.07\"\n        s = re.sub(r\"([€£$])([0-9]+) (?:and )?¢([0-9]{1,2})\\b\", combine_cents, s)\n        s = re.sub(r\"[€£$]0.([0-9]{1,2})\\b\", extract_cents, s)\n        # write \"one(s)\" instead of \"1(s)\", just for the readability\n        s = re.sub(r\"\\b1(s?)\\b\", r\"one\\1\", s)",
        "type": "code",
        "location": "/whisper/normalizers/english.py:409-438"
    },
    "311": {
        "file_id": 22,
        "content": "This code is using regular expressions to normalize and process text. It separates numbers and currency, handles ordinal numbers, and replaces single digits with their English word representation for readability.",
        "type": "comment"
    },
    "312": {
        "file_id": 22,
        "content": "        return s\n    def __call__(self, s: str):\n        s = self.preprocess(s)\n        s = \" \".join(word for word in self.process_words(s.split()) if word is not None)\n        s = self.postprocess(s)\n        return s\nclass EnglishSpellingNormalizer:\n    \"\"\"\n    Applies British-American spelling mappings as listed in [1].\n    [1] https://www.tysto.com/uk-us-spelling-list.html\n    \"\"\"\n    def __init__(self):\n        mapping_path = os.path.join(os.path.dirname(__file__), \"english.json\")\n        self.mapping = json.load(open(mapping_path))\n    def __call__(self, s: str):\n        return \" \".join(self.mapping.get(word, word) for word in s.split())\nclass EnglishTextNormalizer:\n    def __init__(self):\n        self.ignore_patterns = r\"\\b(hmm|mm|mhm|mmm|uh|um)\\b\"\n        self.replacers = {\n            # common contractions\n            r\"\\bwon't\\b\": \"will not\",\n            r\"\\bcan't\\b\": \"can not\",\n            r\"\\blet's\\b\": \"let us\",\n            r\"\\bain't\\b\": \"aint\",\n            r\"\\by'all\\b\": \"you all\",\n            r\"\\bwanna\\b\": \"want to\",",
        "type": "code",
        "location": "/whisper/normalizers/english.py:440-475"
    },
    "313": {
        "file_id": 22,
        "content": "Class \"EnglishSpellingNormalizer\" applies British-American spelling mappings from a JSON file.\nClass \"EnglishTextNormalizer\" normalizes English text by ignoring certain patterns and replacing common contractions.",
        "type": "comment"
    },
    "314": {
        "file_id": 22,
        "content": "            r\"\\bgotta\\b\": \"got to\",\n            r\"\\bgonna\\b\": \"going to\",\n            r\"\\bi'ma\\b\": \"i am going to\",\n            r\"\\bimma\\b\": \"i am going to\",\n            r\"\\bwoulda\\b\": \"would have\",\n            r\"\\bcoulda\\b\": \"could have\",\n            r\"\\bshoulda\\b\": \"should have\",\n            r\"\\bma'am\\b\": \"madam\",\n            # contractions in titles/prefixes\n            r\"\\bmr\\b\": \"mister \",\n            r\"\\bmrs\\b\": \"missus \",\n            r\"\\bst\\b\": \"saint \",\n            r\"\\bdr\\b\": \"doctor \",\n            r\"\\bprof\\b\": \"professor \",\n            r\"\\bcapt\\b\": \"captain \",\n            r\"\\bgov\\b\": \"governor \",\n            r\"\\bald\\b\": \"alderman \",\n            r\"\\bgen\\b\": \"general \",\n            r\"\\bsen\\b\": \"senator \",\n            r\"\\brep\\b\": \"representative \",\n            r\"\\bpres\\b\": \"president \",\n            r\"\\brev\\b\": \"reverend \",\n            r\"\\bhon\\b\": \"honorable \",\n            r\"\\basst\\b\": \"assistant \",\n            r\"\\bassoc\\b\": \"associate \",\n            r\"\\blt\\b\": \"lieutenant \",\n            r\"\\bcol\\b\": \"colonel \",",
        "type": "code",
        "location": "/whisper/normalizers/english.py:476-502"
    },
    "315": {
        "file_id": 22,
        "content": "This code is defining a list of regular expressions that represent common English contractions and abbreviations. These include phrases like \"gotta\", \"going to\", \"would have\", \"could have\", etc., as well as titles and prefixes such as \"mister\", \"missus\", \"doctor\", etc. The code appears to be part of a natural language processing or text normalization system, where these contractions and abbreviations will likely be expanded or normalized for some purpose.",
        "type": "comment"
    },
    "316": {
        "file_id": 22,
        "content": "            r\"\\bjr\\b\": \"junior \",\n            r\"\\bsr\\b\": \"senior \",\n            r\"\\besq\\b\": \"esquire \",\n            # prefect tenses, ideally it should be any past participles, but it's harder..\n            r\"'d been\\b\": \" had been\",\n            r\"'s been\\b\": \" has been\",\n            r\"'d gone\\b\": \" had gone\",\n            r\"'s gone\\b\": \" has gone\",\n            r\"'d done\\b\": \" had done\",  # \"'s done\" is ambiguous\n            r\"'s got\\b\": \" has got\",\n            # general contractions\n            r\"n't\\b\": \" not\",\n            r\"'re\\b\": \" are\",\n            r\"'s\\b\": \" is\",\n            r\"'d\\b\": \" would\",\n            r\"'ll\\b\": \" will\",\n            r\"'t\\b\": \" not\",\n            r\"'ve\\b\": \" have\",\n            r\"'m\\b\": \" am\",\n        }\n        self.standardize_numbers = EnglishNumberNormalizer()\n        self.standardize_spellings = EnglishSpellingNormalizer()\n    def __call__(self, s: str):\n        s = s.lower()\n        s = re.sub(r\"[<\\[][^>\\]]*[>\\]]\", \"\", s)  # remove words between brackets\n        s = re.sub(r\"\\(([^)]+?)\\)\", \"\", s)  # remove words between parenthesis",
        "type": "code",
        "location": "/whisper/normalizers/english.py:503-530"
    },
    "317": {
        "file_id": 22,
        "content": "This code defines a normalizer for English language text. It uses regular expressions to replace specific patterns, such as contractions and past participles, with their full forms. It also removes words within brackets and parentheses before returning the processed string.",
        "type": "comment"
    },
    "318": {
        "file_id": 22,
        "content": "        s = re.sub(self.ignore_patterns, \"\", s)\n        s = re.sub(r\"\\s+'\", \"'\", s)  # when there's a space before an apostrophe\n        for pattern, replacement in self.replacers.items():\n            s = re.sub(pattern, replacement, s)\n        s = re.sub(r\"(\\d),(\\d)\", r\"\\1\\2\", s)  # remove commas between digits\n        s = re.sub(r\"\\.([^0-9]|$)\", r\" \\1\", s)  # remove periods not followed by numbers\n        s = remove_symbols_and_diacritics(s, keep=\".%$¢€£\")  # keep numeric symbols\n        s = self.standardize_numbers(s)\n        s = self.standardize_spellings(s)\n        # now remove prefix/suffix symbols that are not preceded/followed by numbers\n        s = re.sub(r\"[.$¢€£]([^0-9])\", r\" \\1\", s)\n        s = re.sub(r\"([^0-9])%\", r\"\\1 \", s)\n        s = re.sub(r\"\\s+\", \" \", s)  # replace any successive whitespaces with a space\n        return s",
        "type": "code",
        "location": "/whisper/normalizers/english.py:531-550"
    },
    "319": {
        "file_id": 22,
        "content": "Code normalizes English text by removing special characters, standardizing numbers and spellings, and adjusting whitespace.",
        "type": "comment"
    },
    "320": {
        "file_id": 23,
        "content": "/whisper/timing.py",
        "type": "filepath"
    },
    "321": {
        "file_id": 23,
        "content": "The code applies median filtering and dynamic time warping for comparing sequences, calculates text-to-speech alignment using probabilities, removes hooks, normalizes weights, and merges words with punctuation in an alignment. It also adjusts word timings, considers sentence end marks, and stores probabilities.",
        "type": "summary"
    },
    "322": {
        "file_id": 23,
        "content": "import itertools\nimport subprocess\nimport warnings\nfrom dataclasses import dataclass\nfrom typing import TYPE_CHECKING, List\nimport numba\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom .audio import HOP_LENGTH, SAMPLE_RATE, TOKENS_PER_SECOND\nfrom .tokenizer import Tokenizer\nif TYPE_CHECKING:\n    from .model import Whisper\ndef median_filter(x: torch.Tensor, filter_width: int):\n    \"\"\"Apply a median filter of width `filter_width` along the last dimension of `x`\"\"\"\n    pad_width = filter_width // 2\n    if x.shape[-1] <= pad_width:\n        # F.pad requires the padding width to be smaller than the input dimension\n        return x\n    if (ndim := x.ndim) <= 2:\n        # `F.pad` does not support 1D or 2D inputs for reflect padding but supports 3D and 4D\n        x = x[None, None, :]\n    assert (\n        filter_width > 0 and filter_width % 2 == 1\n    ), \"`filter_width` should be an odd number\"\n    result = None\n    x = F.pad(x, (filter_width // 2, filter_width // 2, 0, 0), mode=\"reflect\")\n    if x.is_cuda:",
        "type": "code",
        "location": "/whisper/timing.py:1-36"
    },
    "323": {
        "file_id": 23,
        "content": "This function applies a median filter to the input tensor `x` along the last dimension, specified by `filter_width`. It also handles padding and supports 3D or 4D inputs.",
        "type": "comment"
    },
    "324": {
        "file_id": 23,
        "content": "        try:\n            from .triton_ops import median_filter_cuda\n            result = median_filter_cuda(x, filter_width)\n        except (RuntimeError, subprocess.CalledProcessError):\n            warnings.warn(\n                \"Failed to launch Triton kernels, likely due to missing CUDA toolkit; \"\n                \"falling back to a slower median kernel implementation...\"\n            )\n    if result is None:\n        # sort() is faster than torch.median (https://github.com/pytorch/pytorch/issues/51450)\n        result = x.unfold(-1, filter_width, 1).sort()[0][..., filter_width // 2]\n    if ndim <= 2:\n        result = result[0, 0]\n    return result\n@numba.jit(nopython=True)\ndef backtrace(trace: np.ndarray):\n    i = trace.shape[0] - 1\n    j = trace.shape[1] - 1\n    trace[0, :] = 2\n    trace[:, 0] = 1\n    result = []\n    while i > 0 or j > 0:\n        result.append((i - 1, j - 1))\n        if trace[i, j] == 0:\n            i -= 1\n            j -= 1\n        elif trace[i, j] == 1:\n            i -= 1\n        elif trace[i, j] == 2:",
        "type": "code",
        "location": "/whisper/timing.py:37-73"
    },
    "325": {
        "file_id": 23,
        "content": "The code attempts to apply a median filter with CUDA if available, and falls back to a slower implementation otherwise. It also includes a function for backtracking through the filtered data.",
        "type": "comment"
    },
    "326": {
        "file_id": 23,
        "content": "            j -= 1\n        else:\n            raise ValueError(\"Unexpected trace[i, j]\")\n    result = np.array(result)\n    return result[::-1, :].T\n@numba.jit(nopython=True, parallel=True)\ndef dtw_cpu(x: np.ndarray):\n    N, M = x.shape\n    cost = np.ones((N + 1, M + 1), dtype=np.float32) * np.inf\n    trace = -np.ones((N + 1, M + 1), dtype=np.float32)\n    cost[0, 0] = 0\n    for j in range(1, M + 1):\n        for i in range(1, N + 1):\n            c0 = cost[i - 1, j - 1]\n            c1 = cost[i - 1, j]\n            c2 = cost[i, j - 1]\n            if c0 < c1 and c0 < c2:\n                c, t = c0, 0\n            elif c1 < c0 and c1 < c2:\n                c, t = c1, 1\n            else:\n                c, t = c2, 2\n            cost[i, j] = x[i - 1, j - 1] + c\n            trace[i, j] = t\n    return backtrace(trace)\ndef dtw_cuda(x, BLOCK_SIZE=1024):\n    from .triton_ops import dtw_kernel\n    M, N = x.shape\n    assert M < BLOCK_SIZE, f\"M should be smaller than {BLOCK_SIZE=}\"\n    x_skew = (\n        F.pad(x, (0, M + 1), value=np.inf).flatten()[: M * (N + M)].reshape(M, N + M)",
        "type": "code",
        "location": "/whisper/timing.py:74-115"
    },
    "327": {
        "file_id": 23,
        "content": "This code contains two functions, `dtw_cpu` and `dtw_cuda`, which implement dynamic time warping (DTW) algorithms using different backends. The `dtw_cpu` function implements the DTW algorithm on the CPU using numpy, while the `dtw_cuda` function uses CUDA for GPU acceleration. The code defines variables, initializes arrays, and performs calculations based on the chosen backend.",
        "type": "comment"
    },
    "328": {
        "file_id": 23,
        "content": "    )\n    x_skew = x_skew.T.contiguous()\n    cost = torch.ones(N + M + 2, M + 2) * np.inf\n    cost[0, 0] = 0\n    cost = cost.cuda()\n    trace = torch.zeros_like(cost, dtype=torch.int32)\n    dtw_kernel[(1,)](\n        cost,\n        trace,\n        x_skew,\n        x_skew.stride(0),\n        cost.stride(0),\n        trace.stride(0),\n        N,\n        M,\n        BLOCK_SIZE=BLOCK_SIZE,\n    )\n    trace = trace.T.flatten()[: (M + 1) * (M + N + 3)].reshape(M + 1, M + N + 3)[\n        :, : N + 1\n    ]\n    return backtrace(trace.cpu().numpy())\ndef dtw(x: torch.Tensor) -> np.ndarray:\n    if x.is_cuda:\n        try:\n            return dtw_cuda(x)\n        except (RuntimeError, subprocess.CalledProcessError):\n            warnings.warn(\n                \"Failed to launch Triton kernels, likely due to missing CUDA toolkit; \"\n                \"falling back to a slower DTW implementation...\"\n            )\n    return dtw_cpu(x.double().cpu().numpy())\n@dataclass\nclass WordTiming:\n    word: str\n    tokens: List[int]\n    start: float\n    end: float\n    probability: float",
        "type": "code",
        "location": "/whisper/timing.py:116-160"
    },
    "329": {
        "file_id": 23,
        "content": "This code implements the dynamic time warping (DTW) algorithm for comparing sequences of data points. The code includes CUDA-accelerated and CPU versions of DTW functions, as well as a class for storing word timing information.",
        "type": "comment"
    },
    "330": {
        "file_id": 23,
        "content": "def find_alignment(\n    model: \"Whisper\",\n    tokenizer: Tokenizer,\n    text_tokens: List[int],\n    mel: torch.Tensor,\n    num_frames: int,\n    *,\n    medfilt_width: int = 7,\n    qk_scale: float = 1.0,\n) -> List[WordTiming]:\n    if len(text_tokens) == 0:\n        return []\n    tokens = torch.tensor(\n        [\n            *tokenizer.sot_sequence,\n            tokenizer.no_timestamps,\n            *text_tokens,\n            tokenizer.eot,\n        ]\n    ).to(model.device)\n    # install hooks on the cross attention layers to retrieve the attention weights\n    QKs = [None] * model.dims.n_text_layer\n    hooks = [\n        block.cross_attn.register_forward_hook(\n            lambda _, ins, outs, index=i: QKs.__setitem__(index, outs[-1][0])\n        )\n        for i, block in enumerate(model.decoder.blocks)\n    ]\n    with torch.no_grad():\n        logits = model(mel.unsqueeze(0), tokens.unsqueeze(0))[0]\n        sampled_logits = logits[len(tokenizer.sot_sequence) :, : tokenizer.eot]\n        token_probs = sampled_logits.softmax(dim=-1)",
        "type": "code",
        "location": "/whisper/timing.py:163-197"
    },
    "331": {
        "file_id": 23,
        "content": "This function finds the alignment between model output and input text tokens. It first creates a tensor of tokens including start-of-text (SOT), no timestamp, text tokens, and end-of-text (EOT). Then, it installs hooks on cross attention layers to retrieve attention weights. Finally, it computes logits and token probabilities using the model and tokenizer.",
        "type": "comment"
    },
    "332": {
        "file_id": 23,
        "content": "        text_token_probs = token_probs[np.arange(len(text_tokens)), text_tokens]\n        text_token_probs = text_token_probs.tolist()\n    for hook in hooks:\n        hook.remove()\n    # heads * tokens * frames\n    weights = torch.stack([QKs[_l][_h] for _l, _h in model.alignment_heads.indices().T])\n    weights = weights[:, :, : num_frames // 2]\n    weights = (weights * qk_scale).softmax(dim=-1)\n    std, mean = torch.std_mean(weights, dim=-2, keepdim=True, unbiased=False)\n    weights = (weights - mean) / std\n    weights = median_filter(weights, medfilt_width)\n    matrix = weights.mean(axis=0)\n    matrix = matrix[len(tokenizer.sot_sequence) : -1]\n    text_indices, time_indices = dtw(-matrix)\n    words, word_tokens = tokenizer.split_to_word_tokens(text_tokens + [tokenizer.eot])\n    if len(word_tokens) <= 1:\n        # return on eot only\n        # >>> np.pad([], (1, 0))\n        # array([0.])\n        # This results in crashes when we lookup jump_times with float, like\n        # IndexError: arrays used as indices must be of integer (or boolean) type",
        "type": "code",
        "location": "/whisper/timing.py:198-222"
    },
    "333": {
        "file_id": 23,
        "content": "This code calculates text-to-speech alignment using Dynamic Time Warping (DTW) algorithm. It first computes text and time token probabilities, removes hooks if any, stacks the query and key matrices from the model's alignment heads, selects relevant frames, normalizes the weights, applies median filtering, calculates mean matrix, excludes start-of-text (SOT) and end-of-text (EOT) tokens, computes DTW using text and time indices, splits text into word tokens, and finally returns if there is only one word token.",
        "type": "comment"
    },
    "334": {
        "file_id": 23,
        "content": "        return []\n    word_boundaries = np.pad(np.cumsum([len(t) for t in word_tokens[:-1]]), (1, 0))\n    jumps = np.pad(np.diff(text_indices), (1, 0), constant_values=1).astype(bool)\n    jump_times = time_indices[jumps] / TOKENS_PER_SECOND\n    start_times = jump_times[word_boundaries[:-1]]\n    end_times = jump_times[word_boundaries[1:]]\n    word_probabilities = [\n        np.mean(text_token_probs[i:j])\n        for i, j in zip(word_boundaries[:-1], word_boundaries[1:])\n    ]\n    return [\n        WordTiming(word, tokens, start, end, probability)\n        for word, tokens, start, end, probability in zip(\n            words, word_tokens, start_times, end_times, word_probabilities\n        )\n    ]\ndef merge_punctuations(alignment: List[WordTiming], prepended: str, appended: str):\n    # merge prepended punctuations\n    i = len(alignment) - 2\n    j = len(alignment) - 1\n    while i >= 0:\n        previous = alignment[i]\n        following = alignment[j]\n        if previous.word.startswith(\" \") and previous.word.strip() in prepended:",
        "type": "code",
        "location": "/whisper/timing.py:223-250"
    },
    "335": {
        "file_id": 23,
        "content": "Function to calculate timing and probabilities for each word in the text\n\nThis function calculates start and end times for each word, as well as their probability. It returns a list of WordTiming objects containing word information with their respective timings and probabilities.",
        "type": "comment"
    },
    "336": {
        "file_id": 23,
        "content": "            # prepend it to the following word\n            following.word = previous.word + following.word\n            following.tokens = previous.tokens + following.tokens\n            previous.word = \"\"\n            previous.tokens = []\n        else:\n            j = i\n        i -= 1\n    # merge appended punctuations\n    i = 0\n    j = 1\n    while j < len(alignment):\n        previous = alignment[i]\n        following = alignment[j]\n        if not previous.word.endswith(\" \") and following.word in appended:\n            # append it to the previous word\n            previous.word = previous.word + following.word\n            previous.tokens = previous.tokens + following.tokens\n            following.word = \"\"\n            following.tokens = []\n        else:\n            i = j\n        j += 1\ndef add_word_timestamps(\n    *,\n    segments: List[dict],\n    model: \"Whisper\",\n    tokenizer: Tokenizer,\n    mel: torch.Tensor,\n    num_frames: int,\n    prepend_punctuations: str = \"\\\"'“¿([{-\",\n    append_punctuations: str = \"\\\"'.。,，!！?？:：”)]}、\",",
        "type": "code",
        "location": "/whisper/timing.py:251-285"
    },
    "337": {
        "file_id": 23,
        "content": "This code is responsible for merging words and timestamps in a given alignment. It first prepends the next word with any previously appended punctuations, then iterates over the alignment to merge words that follow non-space ending words with appended punctuations by concatenating them. This function takes segments, model, tokenizer, mel spectrogram, number of frames, and optional parameters for prepend and append punctuation.",
        "type": "comment"
    },
    "338": {
        "file_id": 23,
        "content": "    last_speech_timestamp: float,\n    **kwargs,\n):\n    if len(segments) == 0:\n        return\n    text_tokens_per_segment = [\n        [token for token in segment[\"tokens\"] if token < tokenizer.eot]\n        for segment in segments\n    ]\n    text_tokens = list(itertools.chain.from_iterable(text_tokens_per_segment))\n    alignment = find_alignment(model, tokenizer, text_tokens, mel, num_frames, **kwargs)\n    word_durations = np.array([t.end - t.start for t in alignment])\n    word_durations = word_durations[word_durations.nonzero()]\n    median_duration = np.median(word_durations) if len(word_durations) > 0 else 0.0\n    median_duration = min(0.7, float(median_duration))\n    max_duration = median_duration * 2\n    # hack: truncate long words at sentence boundaries.\n    # a better segmentation algorithm based on VAD should be able to replace this.\n    if len(word_durations) > 0:\n        sentence_end_marks = \".。!！?？\"\n        # ensure words at sentence boundaries are not longer than twice the median word duration.\n        for i in range(1, len(alignment)):",
        "type": "code",
        "location": "/whisper/timing.py:286-310"
    },
    "339": {
        "file_id": 23,
        "content": "Calculates median word duration and truncates long words at sentence boundaries for better speech synthesis.",
        "type": "comment"
    },
    "340": {
        "file_id": 23,
        "content": "            if alignment[i].end - alignment[i].start > max_duration:\n                if alignment[i].word in sentence_end_marks:\n                    alignment[i].end = alignment[i].start + max_duration\n                elif alignment[i - 1].word in sentence_end_marks:\n                    alignment[i].start = alignment[i].end - max_duration\n    merge_punctuations(alignment, prepend_punctuations, append_punctuations)\n    time_offset = segments[0][\"seek\"] * HOP_LENGTH / SAMPLE_RATE\n    word_index = 0\n    for segment, text_tokens in zip(segments, text_tokens_per_segment):\n        saved_tokens = 0\n        words = []\n        while word_index < len(alignment) and saved_tokens < len(text_tokens):\n            timing = alignment[word_index]\n            if timing.word:\n                words.append(\n                    dict(\n                        word=timing.word,\n                        start=round(time_offset + timing.start, 2),\n                        end=round(time_offset + timing.end, 2),\n                        probability=timing.probability,",
        "type": "code",
        "location": "/whisper/timing.py:311-335"
    },
    "341": {
        "file_id": 23,
        "content": "This code is adjusting the timing of words in an alignment list based on a maximum duration and sentence end marks. It also calculates time offsets for segments and extracts words from the alignment, storing their start and end times along with probabilities.",
        "type": "comment"
    },
    "342": {
        "file_id": 23,
        "content": "                    )\n                )\n            saved_tokens += len(timing.tokens)\n            word_index += 1\n        # hack: truncate long words at segment boundaries.\n        # a better segmentation algorithm based on VAD should be able to replace this.\n        if len(words) > 0:\n            # ensure the first and second word after a pause is not longer than\n            # twice the median word duration.\n            if words[0][\"end\"] - last_speech_timestamp > median_duration * 4 and (\n                words[0][\"end\"] - words[0][\"start\"] > max_duration\n                or (\n                    len(words) > 1\n                    and words[1][\"end\"] - words[0][\"start\"] > max_duration * 2\n                )\n            ):\n                if (\n                    len(words) > 1\n                    and words[1][\"end\"] - words[1][\"start\"] > max_duration\n                ):\n                    boundary = max(words[1][\"end\"] / 2, words[1][\"end\"] - max_duration)\n                    words[0][\"end\"] = words[1][\"start\"] = boundary",
        "type": "code",
        "location": "/whisper/timing.py:336-359"
    },
    "343": {
        "file_id": 23,
        "content": "This code is performing a segmentation algorithm for speech by truncating long words at segment boundaries. It checks the duration of words and ensures that no word exceeds twice the median word duration or that the second word after a pause does not exceed the maximum duration. If necessary, it adjusts the word endings to fit these criteria.",
        "type": "comment"
    },
    "344": {
        "file_id": 23,
        "content": "                words[0][\"start\"] = max(0, words[0][\"end\"] - max_duration)\n            # prefer the segment-level start timestamp if the first word is too long.\n            if (\n                segment[\"start\"] < words[0][\"end\"]\n                and segment[\"start\"] - 0.5 > words[0][\"start\"]\n            ):\n                words[0][\"start\"] = max(\n                    0, min(words[0][\"end\"] - median_duration, segment[\"start\"])\n                )\n            else:\n                segment[\"start\"] = words[0][\"start\"]\n            # prefer the segment-level end timestamp if the last word is too long.\n            if (\n                segment[\"end\"] > words[-1][\"start\"]\n                and segment[\"end\"] + 0.5 < words[-1][\"end\"]\n            ):\n                words[-1][\"end\"] = max(\n                    words[-1][\"start\"] + median_duration, segment[\"end\"]\n                )\n            else:\n                segment[\"end\"] = words[-1][\"end\"]\n            last_speech_timestamp = segment[\"end\"]\n        segment[\"words\"] = words",
        "type": "code",
        "location": "/whisper/timing.py:360-386"
    },
    "345": {
        "file_id": 23,
        "content": "This code adjusts word start and end timestamps to fit within the segment timestamps. It prefers segment-level timestamps if a word extends beyond the segment, ensuring the segment remains complete.",
        "type": "comment"
    },
    "346": {
        "file_id": 24,
        "content": "/whisper/tokenizer.py",
        "type": "filepath"
    },
    "347": {
        "file_id": 24,
        "content": "The Tokenizer class in the code uses tiktoken library for efficient text tokenization, supporting various languages and special tokens for different tasks such as translation and transcribe, while also handling speaker tags, non-speech annotations, EOT, SOT, and noise suppression for improved performance.",
        "type": "summary"
    },
    "348": {
        "file_id": 24,
        "content": "import base64\nimport os\nimport string\nfrom dataclasses import dataclass, field\nfrom functools import cached_property, lru_cache\nfrom typing import Dict, List, Optional, Tuple\nimport tiktoken\nLANGUAGES = {\n    \"en\": \"english\",\n    \"zh\": \"chinese\",\n    \"de\": \"german\",\n    \"es\": \"spanish\",\n    \"ru\": \"russian\",\n    \"ko\": \"korean\",\n    \"fr\": \"french\",\n    \"ja\": \"japanese\",\n    \"pt\": \"portuguese\",\n    \"tr\": \"turkish\",\n    \"pl\": \"polish\",\n    \"ca\": \"catalan\",\n    \"nl\": \"dutch\",\n    \"ar\": \"arabic\",\n    \"sv\": \"swedish\",\n    \"it\": \"italian\",\n    \"id\": \"indonesian\",\n    \"hi\": \"hindi\",\n    \"fi\": \"finnish\",\n    \"vi\": \"vietnamese\",\n    \"he\": \"hebrew\",\n    \"uk\": \"ukrainian\",\n    \"el\": \"greek\",\n    \"ms\": \"malay\",\n    \"cs\": \"czech\",\n    \"ro\": \"romanian\",\n    \"da\": \"danish\",\n    \"hu\": \"hungarian\",\n    \"ta\": \"tamil\",\n    \"no\": \"norwegian\",\n    \"th\": \"thai\",\n    \"ur\": \"urdu\",\n    \"hr\": \"croatian\",\n    \"bg\": \"bulgarian\",\n    \"lt\": \"lithuanian\",\n    \"la\": \"latin\",\n    \"mi\": \"maori\",\n    \"ml\": \"malayalam\",\n    \"cy\": \"welsh\",\n    \"sk\": \"slovak\",\n    \"te\": \"telugu\",",
        "type": "code",
        "location": "/whisper/tokenizer.py:1-51"
    },
    "349": {
        "file_id": 24,
        "content": "This code is defining a dictionary of language codes and their corresponding language names.",
        "type": "comment"
    },
    "350": {
        "file_id": 24,
        "content": "    \"fa\": \"persian\",\n    \"lv\": \"latvian\",\n    \"bn\": \"bengali\",\n    \"sr\": \"serbian\",\n    \"az\": \"azerbaijani\",\n    \"sl\": \"slovenian\",\n    \"kn\": \"kannada\",\n    \"et\": \"estonian\",\n    \"mk\": \"macedonian\",\n    \"br\": \"breton\",\n    \"eu\": \"basque\",\n    \"is\": \"icelandic\",\n    \"hy\": \"armenian\",\n    \"ne\": \"nepali\",\n    \"mn\": \"mongolian\",\n    \"bs\": \"bosnian\",\n    \"kk\": \"kazakh\",\n    \"sq\": \"albanian\",\n    \"sw\": \"swahili\",\n    \"gl\": \"galician\",\n    \"mr\": \"marathi\",\n    \"pa\": \"punjabi\",\n    \"si\": \"sinhala\",\n    \"km\": \"khmer\",\n    \"sn\": \"shona\",\n    \"yo\": \"yoruba\",\n    \"so\": \"somali\",\n    \"af\": \"afrikaans\",\n    \"oc\": \"occitan\",\n    \"ka\": \"georgian\",\n    \"be\": \"belarusian\",\n    \"tg\": \"tajik\",\n    \"sd\": \"sindhi\",\n    \"gu\": \"gujarati\",\n    \"am\": \"amharic\",\n    \"yi\": \"yiddish\",\n    \"lo\": \"lao\",\n    \"uz\": \"uzbek\",\n    \"fo\": \"faroese\",\n    \"ht\": \"haitian creole\",\n    \"ps\": \"pashto\",\n    \"tk\": \"turkmen\",\n    \"nn\": \"nynorsk\",\n    \"mt\": \"maltese\",\n    \"sa\": \"sanskrit\",\n    \"lb\": \"luxembourgish\",\n    \"my\": \"myanmar\",\n    \"bo\": \"tibetan\",\n    \"tl\": \"tagalog\",\n    \"mg\": \"malagasy\",",
        "type": "code",
        "location": "/whisper/tokenizer.py:52-101"
    },
    "351": {
        "file_id": 24,
        "content": "This code contains a dictionary where keys are language codes and values are the corresponding language names. The languages represented here are diverse, covering various regions and scripts.",
        "type": "comment"
    },
    "352": {
        "file_id": 24,
        "content": "    \"as\": \"assamese\",\n    \"tt\": \"tatar\",\n    \"haw\": \"hawaiian\",\n    \"ln\": \"lingala\",\n    \"ha\": \"hausa\",\n    \"ba\": \"bashkir\",\n    \"jw\": \"javanese\",\n    \"su\": \"sundanese\",\n    \"yue\": \"cantonese\",\n}\n# language code lookup by name, with a few language aliases\nTO_LANGUAGE_CODE = {\n    **{language: code for code, language in LANGUAGES.items()},\n    \"burmese\": \"my\",\n    \"valencian\": \"ca\",\n    \"flemish\": \"nl\",\n    \"haitian\": \"ht\",\n    \"letzeburgesch\": \"lb\",\n    \"pushto\": \"ps\",\n    \"panjabi\": \"pa\",\n    \"moldavian\": \"ro\",\n    \"moldovan\": \"ro\",\n    \"sinhalese\": \"si\",\n    \"castilian\": \"es\",\n    \"mandarin\": \"zh\",\n}\n@dataclass\nclass Tokenizer:\n    \"\"\"A thin wrapper around `tiktoken` providing quick access to special tokens\"\"\"\n    encoding: tiktoken.Encoding\n    num_languages: int\n    language: Optional[str] = None\n    task: Optional[str] = None\n    sot_sequence: Tuple[int] = ()\n    special_tokens: Dict[str, int] = field(default_factory=dict)\n    def __post_init__(self):\n        for special in self.encoding.special_tokens_set:\n            special_token = self.encoding.encode_single_token(special)",
        "type": "code",
        "location": "/whisper/tokenizer.py:102-144"
    },
    "353": {
        "file_id": 24,
        "content": "This code defines a class called Tokenizer that wraps around the `tiktoken` library. It provides quick access to special tokens and supports specifying a language, task, and start-of-text (SOT) sequence. The code also includes a dictionary mapping language aliases to their respective language codes for easier lookup.",
        "type": "comment"
    },
    "354": {
        "file_id": 24,
        "content": "            self.special_tokens[special] = special_token\n        sot: int = self.special_tokens[\"<|startoftranscript|>\"]\n        translate: int = self.special_tokens[\"<|translate|>\"]\n        transcribe: int = self.special_tokens[\"<|transcribe|>\"]\n        langs = tuple(LANGUAGES.keys())[: self.num_languages]\n        sot_sequence = [sot]\n        if self.language is not None:\n            sot_sequence.append(sot + 1 + langs.index(self.language))\n        if self.task is not None:\n            task_token: int = transcribe if self.task == \"transcribe\" else translate\n            sot_sequence.append(task_token)\n        self.sot_sequence = tuple(sot_sequence)\n    def encode(self, text, **kwargs):\n        return self.encoding.encode(text, **kwargs)\n    def decode(self, token_ids: List[int], **kwargs) -> str:\n        token_ids = [t for t in token_ids if t < self.timestamp_begin]\n        return self.encoding.decode(token_ids, **kwargs)\n    def decode_with_timestamps(self, token_ids: List[int], **kwargs) -> str:\n        \"\"\"",
        "type": "code",
        "location": "/whisper/tokenizer.py:145-169"
    },
    "355": {
        "file_id": 24,
        "content": "This code defines a class for tokenizing text with special tokens, language information, and task information. It also includes methods to encode and decode tokenized text.",
        "type": "comment"
    },
    "356": {
        "file_id": 24,
        "content": "        Timestamp tokens are above other special tokens' id range and are ignored by `decode()`.\n        This method decodes given tokens with timestamps tokens annotated, e.g. \"<|1.08|>\".\n        \"\"\"\n        return self.encoding.decode(token_ids, **kwargs)\n    @cached_property\n    def eot(self) -> int:\n        return self.encoding.eot_token\n    @cached_property\n    def transcribe(self) -> int:\n        return self.special_tokens[\"<|transcribe|>\"]\n    @cached_property\n    def translate(self) -> int:\n        return self.special_tokens[\"<|translate|>\"]\n    @cached_property\n    def sot(self) -> int:\n        return self.special_tokens[\"<|startoftranscript|>\"]\n    @cached_property\n    def sot_lm(self) -> int:\n        return self.special_tokens[\"<|startoflm|>\"]\n    @cached_property\n    def sot_prev(self) -> int:\n        return self.special_tokens[\"<|startofprev|>\"]\n    @cached_property\n    def no_speech(self) -> int:\n        return self.special_tokens[\"<|nospeech|>\"]\n    @cached_property\n    def no_timestamps(self) -> int:",
        "type": "code",
        "location": "/whisper/tokenizer.py:170-204"
    },
    "357": {
        "file_id": 24,
        "content": "The code defines a tokenizer class with properties for various special tokens like end-of-transcript (eot), transcribe, translate, start of transcript (sot), start of language model (sot_lm), start of previous transcript (sot_prev), no speech, and no timestamps. The decode method decodes given tokens with timestamps annotated using the encoding's decode function.",
        "type": "comment"
    },
    "358": {
        "file_id": 24,
        "content": "        return self.special_tokens[\"<|notimestamps|>\"]\n    @cached_property\n    def timestamp_begin(self) -> int:\n        return self.special_tokens[\"<|0.00|>\"]\n    @cached_property\n    def language_token(self) -> int:\n        \"\"\"Returns the token id corresponding to the value of the `language` field\"\"\"\n        if self.language is None:\n            raise ValueError(\"This tokenizer does not have language token configured\")\n        return self.to_language_token(self.language)\n    def to_language_token(self, language):\n        if token := self.special_tokens.get(f\"<|{language}|>\", None):\n            return token\n        raise KeyError(f\"Language {language} not found in tokenizer.\")\n    @cached_property\n    def all_language_tokens(self) -> Tuple[int]:\n        result = []\n        for token, token_id in self.special_tokens.items():\n            if token.strip(\"<|>\") in LANGUAGES:\n                result.append(token_id)\n        return tuple(result)[: self.num_languages]\n    @cached_property\n    def all_language_codes(self) -> Tuple[str]:",
        "type": "code",
        "location": "/whisper/tokenizer.py:205-234"
    },
    "359": {
        "file_id": 24,
        "content": "This code is a part of a tokenizer class for a language model. It includes properties and methods to handle special tokens such as \"<|notimestamps|>\", timestamp tokens like \"<|0.00|>\", and language-specific tokens. The `to_language_token` method returns the token id corresponding to the input language, while `all_language_tokens` and `all_language_codes` return tuples of all language tokens and codes respectively.",
        "type": "comment"
    },
    "360": {
        "file_id": 24,
        "content": "        return tuple(self.decode([_l]).strip(\"<|>\") for _l in self.all_language_tokens)\n    @cached_property\n    def sot_sequence_including_notimestamps(self) -> Tuple[int]:\n        return tuple(list(self.sot_sequence) + [self.no_timestamps])\n    @cached_property\n    def non_speech_tokens(self) -> Tuple[int]:\n        \"\"\"\n        Returns the list of tokens to suppress in order to avoid any speaker tags or non-speech\n        annotations, to prevent sampling texts that are not actually spoken in the audio, e.g.\n        - ♪♪♪\n        - ( SPEAKING FOREIGN LANGUAGE )\n        - [DAVID] Hey there,\n        keeping basic punctuations like commas, periods, question marks, exclamation points, etc.\n        \"\"\"\n        symbols = list('\"#()*+/:;<=>@[\\\\]^_`{|}~「」『』')\n        symbols += (\n            \"<< >> <<< >>> -- --- -( -[ (' (\\\" (( )) ((( ))) [[ ]] {{ }} ♪♪ ♪♪♪\".split()\n        )\n        # symbols that may be a single token or multiple tokens depending on the tokenizer.\n        # In case they're multiple tokens, suppress the first token, which is safe because:",
        "type": "code",
        "location": "/whisper/tokenizer.py:235-259"
    },
    "361": {
        "file_id": 24,
        "content": "This code defines a tokenizer class with various properties and methods for handling language tokens, speaker tags, non-speech annotations, and punctuations. It includes functions to decode language tokens, create a sequence of start of text (SOT) including no time stamps, and a list of non-speech tokens to suppress for accurate sampling of spoken audio.",
        "type": "comment"
    },
    "362": {
        "file_id": 24,
        "content": "        # These are between U+2640 and U+267F miscellaneous symbols that are okay to suppress\n        # in generations, and in the 3-byte UTF-8 representation they share the first two bytes.\n        miscellaneous = set(\"♩♪♫♬♭♮♯\")\n        assert all(0x2640 <= ord(c) <= 0x267F for c in miscellaneous)\n        # allow hyphens \"-\" and single quotes \"'\" between words, but not at the beginning of a word\n        result = {self.encoding.encode(\" -\")[0], self.encoding.encode(\" '\")[0]}\n        for symbol in symbols + list(miscellaneous):\n            for tokens in [\n                self.encoding.encode(symbol),\n                self.encoding.encode(\" \" + symbol),\n            ]:\n                if len(tokens) == 1 or symbol in miscellaneous:\n                    result.add(tokens[0])\n        return tuple(sorted(result))\n    def split_to_word_tokens(self, tokens: List[int]):\n        if self.language in {\"zh\", \"ja\", \"th\", \"lo\", \"my\", \"yue\"}:\n            # These languages don't typically use spaces, so it is difficult to split words",
        "type": "code",
        "location": "/whisper/tokenizer.py:260-279"
    },
    "363": {
        "file_id": 24,
        "content": "This function creates a set of characters to suppress and allows hyphens and single quotes between words. It then encodes various symbols, checks if they are 1 character long or in the miscellaneous set, and adds them to the result set. Finally, it sorts and returns the result set.",
        "type": "comment"
    },
    "364": {
        "file_id": 24,
        "content": "            # without morpheme analysis. Here, we instead split words at any\n            # position where the tokens are decoded as valid unicode points\n            return self.split_tokens_on_unicode(tokens)\n        return self.split_tokens_on_spaces(tokens)\n    def split_tokens_on_unicode(self, tokens: List[int]):\n        decoded_full = self.decode_with_timestamps(tokens)\n        replacement_char = \"\\ufffd\"\n        words = []\n        word_tokens = []\n        current_tokens = []\n        unicode_offset = 0\n        for token in tokens:\n            current_tokens.append(token)\n            decoded = self.decode_with_timestamps(current_tokens)\n            if (\n                replacement_char not in decoded\n                or decoded_full[unicode_offset + decoded.index(replacement_char)]\n                == replacement_char\n            ):\n                words.append(decoded)\n                word_tokens.append(current_tokens)\n                current_tokens = []\n                unicode_offset += len(decoded)\n        return words, word_tokens",
        "type": "code",
        "location": "/whisper/tokenizer.py:280-309"
    },
    "365": {
        "file_id": 24,
        "content": "This code splits tokens into words by checking if they can be decoded as valid unicode points. If a token can't be decoded, it considers the preceding word complete and moves on to the next word. It returns both the decoded text (words) and the original token list (word_tokens).",
        "type": "comment"
    },
    "366": {
        "file_id": 24,
        "content": "    def split_tokens_on_spaces(self, tokens: List[int]):\n        subwords, subword_tokens_list = self.split_tokens_on_unicode(tokens)\n        words = []\n        word_tokens = []\n        for subword, subword_tokens in zip(subwords, subword_tokens_list):\n            special = subword_tokens[0] >= self.eot\n            with_space = subword.startswith(\" \")\n            punctuation = subword.strip() in string.punctuation\n            if special or with_space or punctuation or len(words) == 0:\n                words.append(subword)\n                word_tokens.append(subword_tokens)\n            else:\n                words[-1] = words[-1] + subword\n                word_tokens[-1].extend(subword_tokens)\n        return words, word_tokens\n@lru_cache(maxsize=None)\ndef get_encoding(name: str = \"gpt2\", num_languages: int = 99):\n    vocab_path = os.path.join(os.path.dirname(__file__), \"assets\", f\"{name}.tiktoken\")\n    ranks = {\n        base64.b64decode(token): int(rank)\n        for token, rank in (line.split() for line in open(vocab_path) if line)",
        "type": "code",
        "location": "/whisper/tokenizer.py:311-335"
    },
    "367": {
        "file_id": 24,
        "content": "This code splits tokens into subwords, and then further splits them based on special characters, words with spaces, or punctuation. It returns a list of words and corresponding token lists. The `get_encoding` function loads vocabulary information from a file and returns a function for encoding strings to tokens based on the specified name and number of languages.",
        "type": "comment"
    },
    "368": {
        "file_id": 24,
        "content": "    }\n    n_vocab = len(ranks)\n    special_tokens = {}\n    specials = [\n        \"<|endoftext|>\",\n        \"<|startoftranscript|>\",\n        *[f\"<|{lang}|>\" for lang in list(LANGUAGES.keys())[:num_languages]],\n        \"<|translate|>\",\n        \"<|transcribe|>\",\n        \"<|startoflm|>\",\n        \"<|startofprev|>\",\n        \"<|nospeech|>\",\n        \"<|notimestamps|>\",\n        *[f\"<|{i * 0.02:.2f}|>\" for i in range(1501)],\n    ]\n    for token in specials:\n        special_tokens[token] = n_vocab\n        n_vocab += 1\n    return tiktoken.Encoding(\n        name=os.path.basename(vocab_path),\n        explicit_n_vocab=n_vocab,\n        pat_str=r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\",\n        mergeable_ranks=ranks,\n        special_tokens=special_tokens,\n    )\n@lru_cache(maxsize=None)\ndef get_tokenizer(\n    multilingual: bool,\n    *,\n    num_languages: int = 99,\n    language: Optional[str] = None,\n    task: Optional[str] = None,  # Literal[\"transcribe\", \"translate\", None]\n) -> Tokenizer:\n    if language is not None:",
        "type": "code",
        "location": "/whisper/tokenizer.py:336-374"
    },
    "369": {
        "file_id": 24,
        "content": "This code defines a function that returns a tokenizer object based on specified parameters such as multilingual, num_languages, and language. The returned tokenizer is implemented using the tiktoken Encoding class and includes special tokens for tasks like translation and transcribe. The code also handles end-of-text and start-of-transcript markers, different languages, and specific time intervals. It creates a list of special tokens and assigns their corresponding ranks in the mergeable_ranks parameter. Additionally, it caches the function to improve performance by using the @lru_cache decorator.",
        "type": "comment"
    },
    "370": {
        "file_id": 24,
        "content": "        language = language.lower()\n        if language not in LANGUAGES:\n            if language in TO_LANGUAGE_CODE:\n                language = TO_LANGUAGE_CODE[language]\n            else:\n                raise ValueError(f\"Unsupported language: {language}\")\n    if multilingual:\n        encoding_name = \"multilingual\"\n        language = language or \"en\"\n        task = task or \"transcribe\"\n    else:\n        encoding_name = \"gpt2\"\n        language = None\n        task = None\n    encoding = get_encoding(name=encoding_name, num_languages=num_languages)\n    return Tokenizer(\n        encoding=encoding, num_languages=num_languages, language=language, task=task\n    )",
        "type": "code",
        "location": "/whisper/tokenizer.py:375-395"
    },
    "371": {
        "file_id": 24,
        "content": "This code checks the given language and initializes a tokenizer based on its properties. If the language is not supported, it raises an error. The encoding name and task are determined based on whether the input is multilingual or not. Then, it returns a tokenizer object with the specified parameters.",
        "type": "comment"
    },
    "372": {
        "file_id": 25,
        "content": "/whisper/transcribe.py",
        "type": "filepath"
    },
    "373": {
        "file_id": 25,
        "content": "The code handles speech transcription with Whisper model libraries, providing customizable parameters and managing segments, silence, and seek values. It transcribes audio files with timestamps, punctuation, and function options while checking input language and detecting hallucination using silence thresholds.",
        "type": "summary"
    },
    "374": {
        "file_id": 25,
        "content": "import argparse\nimport os\nimport traceback\nimport warnings\nfrom typing import TYPE_CHECKING, List, Optional, Tuple, Union\nimport numpy as np\nimport torch\nimport tqdm\nfrom .audio import (\n    FRAMES_PER_SECOND,\n    HOP_LENGTH,\n    N_FRAMES,\n    N_SAMPLES,\n    SAMPLE_RATE,\n    log_mel_spectrogram,\n    pad_or_trim,\n)\nfrom .decoding import DecodingOptions, DecodingResult\nfrom .timing import add_word_timestamps\nfrom .tokenizer import LANGUAGES, TO_LANGUAGE_CODE, get_tokenizer\nfrom .utils import (\n    exact_div,\n    format_timestamp,\n    get_end,\n    get_writer,\n    make_safe,\n    optional_float,\n    optional_int,\n    str2bool,\n)\nif TYPE_CHECKING:\n    from .model import Whisper\ndef transcribe(\n    model: \"Whisper\",\n    audio: Union[str, np.ndarray, torch.Tensor],\n    *,\n    verbose: Optional[bool] = None,\n    temperature: Union[float, Tuple[float, ...]] = (0.0, 0.2, 0.4, 0.6, 0.8, 1.0),\n    compression_ratio_threshold: Optional[float] = 2.4,\n    logprob_threshold: Optional[float] = -1.0,\n    no_speech_threshold: Optional[float] = 0.6,",
        "type": "code",
        "location": "/whisper/transcribe.py:1-46"
    },
    "375": {
        "file_id": 25,
        "content": "This code is importing necessary libraries and modules for the Whisper model to transcribe audio. It defines a function `transcribe` that takes in an audio file, optional arguments for verbose, temperature, compression_ratio_threshold, logprob_threshold, and no_speech_threshold. The function uses the Whisper model to transcribe the given audio.",
        "type": "comment"
    },
    "376": {
        "file_id": 25,
        "content": "    condition_on_previous_text: bool = True,\n    initial_prompt: Optional[str] = None,\n    word_timestamps: bool = False,\n    prepend_punctuations: str = \"\\\"'“¿([{-\",\n    append_punctuations: str = \"\\\"'.。,，!！?？:：”)]}、\",\n    clip_timestamps: Union[str, List[float]] = \"0\",\n    hallucination_silence_threshold: Optional[float] = None,\n    **decode_options,\n):\n    \"\"\"\n    Transcribe an audio file using Whisper\n    Parameters\n    ----------\n    model: Whisper\n        The Whisper model instance\n    audio: Union[str, np.ndarray, torch.Tensor]\n        The path to the audio file to open, or the audio waveform\n    verbose: bool\n        Whether to display the text being decoded to the console. If True, displays all the details,\n        If False, displays minimal details. If None, does not display anything\n    temperature: Union[float, Tuple[float, ...]]\n        Temperature for sampling. It can be a tuple of temperatures, which will be successively used\n        upon failures according to either `compression_ratio_threshold` or `logprob_threshold`.",
        "type": "code",
        "location": "/whisper/transcribe.py:47-73"
    },
    "377": {
        "file_id": 25,
        "content": "This function transcribes an audio file using Whisper. It takes parameters like the model instance, audio file path or waveform, verbosity level for displaying text being decoded, and temperatures for sampling during the transcription process.",
        "type": "comment"
    },
    "378": {
        "file_id": 25,
        "content": "    compression_ratio_threshold: float\n        If the gzip compression ratio is above this value, treat as failed\n    logprob_threshold: float\n        If the average log probability over sampled tokens is below this value, treat as failed\n    no_speech_threshold: float\n        If the no_speech probability is higher than this value AND the average log probability\n        over sampled tokens is below `logprob_threshold`, consider the segment as silent\n    condition_on_previous_text: bool\n        if True, the previous output of the model is provided as a prompt for the next window;\n        disabling may make the text inconsistent across windows, but the model becomes less prone to\n        getting stuck in a failure loop, such as repetition looping or timestamps going out of sync.\n    word_timestamps: bool\n        Extract word-level timestamps using the cross-attention pattern and dynamic time warping,\n        and include the timestamps for each word in each segment.\n    prepend_punctuations: str\n        If word_timestamps is True, merge these punctuation symbols with the next word",
        "type": "code",
        "location": "/whisper/transcribe.py:75-95"
    },
    "379": {
        "file_id": 25,
        "content": "These variables define the thresholds and conditions for determining if a segment is successful or not, whether to condition on previous text, extract word-level timestamps, and how to handle punctuation symbols in the output.",
        "type": "comment"
    },
    "380": {
        "file_id": 25,
        "content": "    append_punctuations: str\n        If word_timestamps is True, merge these punctuation symbols with the previous word\n    initial_prompt: Optional[str]\n        Optional text to provide as a prompt for the first window. This can be used to provide, or\n        \"prompt-engineer\" a context for transcription, e.g. custom vocabularies or proper nouns\n        to make it more likely to predict those word correctly.\n    decode_options: dict\n        Keyword arguments to construct `DecodingOptions` instances\n    clip_timestamps: Union[str, List[float]]\n        Comma-separated list start,end,start,end,... timestamps (in seconds) of clips to process.\n        The last end timestamp defaults to the end of the file.\n    hallucination_silence_threshold: Optional[float]\n        When word_timestamps is True, skip silent periods longer than this threshold (in seconds)\n        when a possible hallucination is detected\n    Returns\n    -------\n    A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and",
        "type": "code",
        "location": "/whisper/transcribe.py:97-118"
    },
    "381": {
        "file_id": 25,
        "content": "This function takes optional parameters for prompt, decoding options, clip timestamps, and hallucination silence threshold to transcribe speech into text. It returns a dictionary containing the resulting text and segment-level details.",
        "type": "comment"
    },
    "382": {
        "file_id": 25,
        "content": "    the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n    \"\"\"\n    dtype = torch.float16 if decode_options.get(\"fp16\", True) else torch.float32\n    if model.device == torch.device(\"cpu\"):\n        if torch.cuda.is_available():\n            warnings.warn(\"Performing inference on CPU when CUDA is available\")\n        if dtype == torch.float16:\n            warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n            dtype = torch.float32\n    if dtype == torch.float32:\n        decode_options[\"fp16\"] = False\n    # Pad 30-seconds of silence to the input audio, for slicing\n    mel = log_mel_spectrogram(audio, model.dims.n_mels, padding=N_SAMPLES)\n    content_frames = mel.shape[-1] - N_FRAMES\n    content_duration = float(content_frames * HOP_LENGTH / SAMPLE_RATE)\n    if decode_options.get(\"language\", None) is None:\n        if not model.is_multilingual:\n            decode_options[\"language\"] = \"en\"\n        else:\n            if verbose:\n                print(",
        "type": "code",
        "location": "/whisper/transcribe.py:119-142"
    },
    "383": {
        "file_id": 25,
        "content": "This code snippet is preparing the audio input for inference by handling the data type, padding silence to the input audio, and setting the language for decoding.\nThe code checks if the device is CPU or GPU and adjusts the data type accordingly. It also adds 30 seconds of silence to the input audio for slicing and calculates the content duration based on the frame size, hop length, and sample rate. If no language is specified in the decode options, it sets a default language if the model is not multilingual or displays a message if the model is multilingual.",
        "type": "comment"
    },
    "384": {
        "file_id": 25,
        "content": "                    \"Detecting language using up to the first 30 seconds. Use `--language` to specify the language\"\n                )\n            mel_segment = pad_or_trim(mel, N_FRAMES).to(model.device).to(dtype)\n            _, probs = model.detect_language(mel_segment)\n            decode_options[\"language\"] = max(probs, key=probs.get)\n            if verbose is not None:\n                print(\n                    f\"Detected language: {LANGUAGES[decode_options['language']].title()}\"\n                )\n    language: str = decode_options[\"language\"]\n    task: str = decode_options.get(\"task\", \"transcribe\")\n    tokenizer = get_tokenizer(\n        model.is_multilingual,\n        num_languages=model.num_languages,\n        language=language,\n        task=task,\n    )\n    if isinstance(clip_timestamps, str):\n        clip_timestamps = [\n            float(ts) for ts in (clip_timestamps.split(\",\") if clip_timestamps else [])\n        ]\n    seek_points: List[int] = [round(ts * FRAMES_PER_SECOND) for ts in clip_timestamps]\n    if len(seek_points) == 0:",
        "type": "code",
        "location": "/whisper/transcribe.py:143-167"
    },
    "385": {
        "file_id": 25,
        "content": "The code is detecting the language of an audio clip using the first 30 seconds and then using that detected language to decide which tokenizer to use for further processing.",
        "type": "comment"
    },
    "386": {
        "file_id": 25,
        "content": "        seek_points.append(0)\n    if len(seek_points) % 2 == 1:\n        seek_points.append(content_frames)\n    seek_clips: List[Tuple[int, int]] = list(zip(seek_points[::2], seek_points[1::2]))\n    punctuation = \"\\\"'“¿([{-\\\"'.。,，!！?？:：”)]}、\"\n    if word_timestamps and task == \"translate\":\n        warnings.warn(\"Word-level timestamps on translations may not be reliable.\")\n    def decode_with_fallback(segment: torch.Tensor) -> DecodingResult:\n        temperatures = (\n            [temperature] if isinstance(temperature, (int, float)) else temperature\n        )\n        decode_result = None\n        for t in temperatures:\n            kwargs = {**decode_options}\n            if t > 0:\n                # disable beam_size and patience when t > 0\n                kwargs.pop(\"beam_size\", None)\n                kwargs.pop(\"patience\", None)\n            else:\n                # disable best_of when t == 0\n                kwargs.pop(\"best_of\", None)\n            options = DecodingOptions(**kwargs, temperature=t)\n            decode_result = model.decode(segment, options)",
        "type": "code",
        "location": "/whisper/transcribe.py:168-195"
    },
    "387": {
        "file_id": 25,
        "content": "This code segment is preparing data for decoding a model. It creates seek points, a list of punctuation, and sets up temperature values for the decoder. If word-level timestamps are present and the task is translation, it warns about potential unreliability. The function `decode_with_fallback` is defined to decode the segment with different temperatures using the specified decoding options and model.",
        "type": "comment"
    },
    "388": {
        "file_id": 25,
        "content": "            needs_fallback = False\n            if (\n                compression_ratio_threshold is not None\n                and decode_result.compression_ratio > compression_ratio_threshold\n            ):\n                needs_fallback = True  # too repetitive\n            if (\n                logprob_threshold is not None\n                and decode_result.avg_logprob < logprob_threshold\n            ):\n                needs_fallback = True  # average log probability is too low\n            if (\n                no_speech_threshold is not None\n                and decode_result.no_speech_prob > no_speech_threshold\n            ):\n                needs_fallback = False  # silence\n            if not needs_fallback:\n                break\n        return decode_result\n    clip_idx = 0\n    seek = seek_clips[clip_idx][0]\n    input_stride = exact_div(\n        N_FRAMES, model.dims.n_audio_ctx\n    )  # mel frames per output token: 2\n    time_precision = (\n        input_stride * HOP_LENGTH / SAMPLE_RATE\n    )  # time per output token: 0.02 (seconds)",
        "type": "code",
        "location": "/whisper/transcribe.py:197-225"
    },
    "389": {
        "file_id": 25,
        "content": "This code checks if the decoding result requires a fallback, based on three conditions: compression ratio, average log probability, and silence detection. If no fallback is needed, it breaks out of the loop. The code then calculates the number of mel frames per output token and time precision for further processing.",
        "type": "comment"
    },
    "390": {
        "file_id": 25,
        "content": "    all_tokens = []\n    all_segments = []\n    prompt_reset_since = 0\n    if initial_prompt is not None:\n        initial_prompt_tokens = tokenizer.encode(\" \" + initial_prompt.strip())\n        all_tokens.extend(initial_prompt_tokens)\n    else:\n        initial_prompt_tokens = []\n    def new_segment(\n        *, start: float, end: float, tokens: torch.Tensor, result: DecodingResult\n    ):\n        tokens = tokens.tolist()\n        text_tokens = [token for token in tokens if token < tokenizer.eot]\n        return {\n            \"seek\": seek,\n            \"start\": start,\n            \"end\": end,\n            \"text\": tokenizer.decode(text_tokens),\n            \"tokens\": tokens,\n            \"temperature\": result.temperature,\n            \"avg_logprob\": result.avg_logprob,\n            \"compression_ratio\": result.compression_ratio,\n            \"no_speech_prob\": result.no_speech_prob,\n        }\n    # show the progress bar when verbose is False (if True, transcribed text will be printed)\n    with tqdm.tqdm(\n        total=content_frames, unit=\"frames\", disable=verbose is not False",
        "type": "code",
        "location": "/whisper/transcribe.py:226-255"
    },
    "391": {
        "file_id": 25,
        "content": "This code segment initializes variables for storing tokens and segments, handles an optional initial prompt, defines a function for creating new speech segments, and sets up a progress bar.",
        "type": "comment"
    },
    "392": {
        "file_id": 25,
        "content": "    ) as pbar:\n        last_speech_timestamp = 0.0\n        # NOTE: This loop is obscurely flattened to make the diff readable.\n        # A later commit should turn this into a simpler nested loop.\n        # for seek_clip_start, seek_clip_end in seek_clips:\n        #     while seek < seek_clip_end\n        while clip_idx < len(seek_clips):\n            seek_clip_start, seek_clip_end = seek_clips[clip_idx]\n            if seek < seek_clip_start:\n                seek = seek_clip_start\n            if seek >= seek_clip_end:\n                clip_idx += 1\n                if clip_idx < len(seek_clips):\n                    seek = seek_clips[clip_idx][0]\n                continue\n            time_offset = float(seek * HOP_LENGTH / SAMPLE_RATE)\n            window_end_time = float((seek + N_FRAMES) * HOP_LENGTH / SAMPLE_RATE)\n            segment_size = min(N_FRAMES, content_frames - seek, seek_clip_end - seek)\n            mel_segment = mel[:, seek : seek + segment_size]\n            segment_duration = segment_size * HOP_LENGTH / SAMPLE_RATE",
        "type": "code",
        "location": "/whisper/transcribe.py:256-275"
    },
    "393": {
        "file_id": 25,
        "content": "Iterates over seek clips, finding the next segment to transcribe based on seek time and clip boundaries.",
        "type": "comment"
    },
    "394": {
        "file_id": 25,
        "content": "            mel_segment = pad_or_trim(mel_segment, N_FRAMES).to(model.device).to(dtype)\n            decode_options[\"prompt\"] = all_tokens[prompt_reset_since:]\n            result: DecodingResult = decode_with_fallback(mel_segment)\n            tokens = torch.tensor(result.tokens)\n            if no_speech_threshold is not None:\n                # no voice activity check\n                should_skip = result.no_speech_prob > no_speech_threshold\n                if (\n                    logprob_threshold is not None\n                    and result.avg_logprob > logprob_threshold\n                ):\n                    # don't skip if the logprob is high enough, despite the no_speech_prob\n                    should_skip = False\n                if should_skip:\n                    seek += segment_size  # fast-forward to the next segment boundary\n                    continue\n            previous_seek = seek\n            current_segments = []\n            # anomalous words are very long/short/improbable\n            def word_anomaly_score(word: dict) -> float:",
        "type": "code",
        "location": "/whisper/transcribe.py:276-300"
    },
    "395": {
        "file_id": 25,
        "content": "This code segment is responsible for speech recognition and processing in the whisper library. It takes an input audio segment, performs speech recognition using a model, and checks if there is any no-speech activity or anomalous words. If any of these conditions are met, it skips the current segment and moves to the next one. The code also keeps track of the seek position (seek) for fast forwarding to the next segment boundary.",
        "type": "comment"
    },
    "396": {
        "file_id": 25,
        "content": "                probability = word.get(\"probability\", 0.0)\n                duration = word[\"end\"] - word[\"start\"]\n                score = 0.0\n                if probability < 0.15:\n                    score += 1.0\n                if duration < 0.133:\n                    score += (0.133 - duration) * 15\n                if duration > 2.0:\n                    score += duration - 2.0\n                return score\n            def is_segment_anomaly(segment: Optional[dict]) -> bool:\n                if segment is None or not segment[\"words\"]:\n                    return False\n                words = [w for w in segment[\"words\"] if w[\"word\"] not in punctuation]\n                words = words[:8]\n                score = sum(word_anomaly_score(w) for w in words)\n                return score >= 3 or score + 0.01 >= len(words)\n            def next_words_segment(segments: List[dict]) -> Optional[dict]:\n                return next((s for s in segments if s[\"words\"]), None)\n            timestamp_tokens: torch.Tensor = tokens.ge(tokenizer.timestamp_begin)",
        "type": "code",
        "location": "/whisper/transcribe.py:301-323"
    },
    "397": {
        "file_id": 25,
        "content": "This code calculates a score for each segment based on word probability and duration, checks if a segment is anomalous by considering its words and returns the next non-empty segment from a list. It also handles timestamp tokens.",
        "type": "comment"
    },
    "398": {
        "file_id": 25,
        "content": "            single_timestamp_ending = timestamp_tokens[-2:].tolist() == [False, True]\n            consecutive = torch.where(timestamp_tokens[:-1] & timestamp_tokens[1:])[0]\n            consecutive.add_(1)\n            if len(consecutive) > 0:\n                # if the output contains two consecutive timestamp tokens\n                slices = consecutive.tolist()\n                if single_timestamp_ending:\n                    slices.append(len(tokens))\n                last_slice = 0\n                for current_slice in slices:\n                    sliced_tokens = tokens[last_slice:current_slice]\n                    start_timestamp_pos = (\n                        sliced_tokens[0].item() - tokenizer.timestamp_begin\n                    )\n                    end_timestamp_pos = (\n                        sliced_tokens[-1].item() - tokenizer.timestamp_begin\n                    )\n                    current_segments.append(\n                        new_segment(\n                            start=time_offset + start_timestamp_pos * time_precision,",
        "type": "code",
        "location": "/whisper/transcribe.py:324-345"
    },
    "399": {
        "file_id": 25,
        "content": "This code checks for consecutive timestamp tokens and extracts corresponding segments from the input sequence of tokens. If a segment is found, it calculates the start and end timestamp positions and creates a new segment with adjusted time values.",
        "type": "comment"
    }
}