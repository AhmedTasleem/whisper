{
    "200": {
        "file_id": 18,
        "content": "        Returns\n        -------\n        tokens : Sequence[Sequence[Tensor]], length = n_audio\n            sequence of Tensors containing candidate token sequences, for each audio input\n        sum_logprobs : List[List[float]], length = n_audio\n            sequence of cumulative log probabilities corresponding to the above\n        \"\"\"\n        raise NotImplementedError\nclass GreedyDecoder(TokenDecoder):\n    def __init__(self, temperature: float, eot: int):\n        self.temperature = temperature\n        self.eot = eot\n    def update(\n        self, tokens: Tensor, logits: Tensor, sum_logprobs: Tensor\n    ) -> Tuple[Tensor, bool]:\n        if self.temperature == 0:\n            next_tokens = logits.argmax(dim=-1)\n        else:\n            next_tokens = Categorical(logits=logits / self.temperature).sample()\n        logprobs = F.log_softmax(logits.float(), dim=-1)\n        current_logprobs = logprobs[torch.arange(logprobs.shape[0]), next_tokens]\n        sum_logprobs += current_logprobs * (tokens[:, -1] != self.eot)\n        next_tokens[tokens[:, -1] == self.eot] = self.eot",
        "type": "code",
        "location": "/whisper/decoding.py:260-289"
    },
    "201": {
        "file_id": 18,
        "content": "This code defines a GreedyDecoder class that takes temperature and eot (end of text) parameters. It implements an update() function that given tokens, logits, and sum_logprobs, returns updated tokens and a boolean indicating whether the end of text has been reached. If the temperature is 0, it selects the most probable token using argmax. Otherwise, it uses the softmax distribution to sample a token at the specified temperature. It also updates the logprobs and sum_logprobs for each token.",
        "type": "comment"
    },
    "202": {
        "file_id": 18,
        "content": "        tokens = torch.cat([tokens, next_tokens[:, None]], dim=-1)\n        completed = (tokens[:, -1] == self.eot).all()\n        return tokens, completed\n    def finalize(self, tokens: Tensor, sum_logprobs: Tensor):\n        # make sure each sequence has at least one EOT token at the end\n        tokens = F.pad(tokens, (0, 1), value=self.eot)\n        return tokens, sum_logprobs.tolist()\nclass BeamSearchDecoder(TokenDecoder):\n    def __init__(\n        self,\n        beam_size: int,\n        eot: int,\n        inference: Inference,\n        patience: Optional[float] = None,\n    ):\n        self.beam_size = beam_size\n        self.eot = eot\n        self.inference = inference\n        self.patience = patience or 1.0\n        self.max_candidates: int = round(beam_size * self.patience)\n        self.finished_sequences = None\n        assert (\n            self.max_candidates > 0\n        ), f\"Invalid beam size ({beam_size}) or patience ({patience})\"\n    def reset(self):\n        self.finished_sequences = None\n    def update(\n        self, tokens: Tensor, logits: Tensor, sum_logprobs: Tensor",
        "type": "code",
        "location": "/whisper/decoding.py:290-324"
    },
    "203": {
        "file_id": 18,
        "content": "The code defines a BeamSearchDecoder class for decoding sequences using beam search algorithm. It initializes with a beam size, EOT token, inference type, and patience value. It also has methods for resetting and updating the decoder during the decoding process.",
        "type": "comment"
    },
    "204": {
        "file_id": 18,
        "content": "    ) -> Tuple[Tensor, bool]:\n        if tokens.shape[0] % self.beam_size != 0:\n            raise ValueError(f\"{tokens.shape}[0] % {self.beam_size} != 0\")\n        n_audio = tokens.shape[0] // self.beam_size\n        if self.finished_sequences is None:  # for the first update\n            self.finished_sequences = [{} for _ in range(n_audio)]\n        logprobs = F.log_softmax(logits.float(), dim=-1)\n        next_tokens, source_indices, finished_sequences = [], [], []\n        for i in range(n_audio):\n            scores, sources, finished = {}, {}, {}\n            # STEP 1: calculate the cumulative log probabilities for possible candidates\n            for j in range(self.beam_size):\n                idx = i * self.beam_size + j\n                prefix = tokens[idx].tolist()\n                for logprob, token in zip(*logprobs[idx].topk(self.beam_size + 1)):\n                    new_logprob = (sum_logprobs[idx] + logprob).item()\n                    sequence = tuple(prefix + [token.item()])\n                    scores[sequence] = new_logprob",
        "type": "code",
        "location": "/whisper/decoding.py:325-345"
    },
    "205": {
        "file_id": 18,
        "content": "This function divides the input tokens into multiple audio sequences based on the beam size. It checks if the number of tokens is a multiple of the beam size, and raises an error if not. It then calculates cumulative log probabilities for possible candidates in each audio sequence.",
        "type": "comment"
    },
    "206": {
        "file_id": 18,
        "content": "                    sources[sequence] = idx\n            # STEP 2: rank the candidates and keep the top beam_size sequences for each audio\n            saved = 0\n            for sequence in sorted(scores, key=scores.get, reverse=True):\n                if sequence[-1] == self.eot:\n                    finished[sequence] = scores[sequence]\n                else:\n                    sum_logprobs[len(next_tokens)] = scores[sequence]\n                    next_tokens.append(sequence)\n                    source_indices.append(sources[sequence])\n                    saved += 1\n                    if saved == self.beam_size:\n                        break\n            finished_sequences.append(finished)\n        tokens = torch.tensor(next_tokens, device=tokens.device)\n        self.inference.rearrange_kv_cache(source_indices)\n        # add newly finished sequences to self.finished_sequences\n        assert len(self.finished_sequences) == len(finished_sequences)\n        for previously_finished, newly_finished in zip(\n            self.finished_sequences, finished_sequences",
        "type": "code",
        "location": "/whisper/decoding.py:346-370"
    },
    "207": {
        "file_id": 18,
        "content": "This code is ranking and selecting the top N sequences from a list of candidate sequences based on their scores. It keeps track of finished sequences and updates the inference cache with new data.",
        "type": "comment"
    },
    "208": {
        "file_id": 18,
        "content": "        ):\n            for seq in sorted(newly_finished, key=newly_finished.get, reverse=True):\n                if len(previously_finished) >= self.max_candidates:\n                    break  # the candidate list is full\n                previously_finished[seq] = newly_finished[seq]\n        # mark as completed if all audio has enough number of samples\n        completed = all(\n            len(sequences) >= self.max_candidates\n            for sequences in self.finished_sequences\n        )\n        return tokens, completed\n    def finalize(self, preceding_tokens: Tensor, sum_logprobs: Tensor):\n        # collect all finished sequences, including patience, and add unfinished ones if not enough\n        sum_logprobs = sum_logprobs.cpu()\n        for i, sequences in enumerate(self.finished_sequences):\n            if (\n                len(sequences) < self.beam_size\n            ):  # when not enough sequences are finished\n                for j in list(np.argsort(sum_logprobs[i]))[::-1]:\n                    sequence = preceding_tokens[i, j].tolist() + [self.eot]",
        "type": "code",
        "location": "/whisper/decoding.py:371-392"
    },
    "209": {
        "file_id": 18,
        "content": "Code adds more finished sequences to the list if there are not enough. It also marks all sequences as completed if they have enough samples.",
        "type": "comment"
    },
    "210": {
        "file_id": 18,
        "content": "                    sequences[tuple(sequence)] = sum_logprobs[i][j].item()\n                    if len(sequences) >= self.beam_size:\n                        break\n        tokens: List[List[Tensor]] = [\n            [torch.tensor(seq) for seq in sequences.keys()]\n            for sequences in self.finished_sequences\n        ]\n        sum_logprobs: List[List[float]] = [\n            list(sequences.values()) for sequences in self.finished_sequences\n        ]\n        return tokens, sum_logprobs\nclass LogitFilter:\n    def apply(self, logits: Tensor, tokens: Tensor) -> None:\n        \"\"\"Apply any filtering or masking to logits in-place\n        Parameters\n        ----------\n        logits : Tensor, shape = (n_batch, vocab_size)\n            per-token logits of the probability distribution at the current step\n        tokens : Tensor, shape = (n_batch, current_sequence_length)\n            all tokens in the context so far, including the prefix and sot_sequence tokens\n        \"\"\"\n        raise NotImplementedError\nclass SuppressBlank(LogitFilter):",
        "type": "code",
        "location": "/whisper/decoding.py:393-423"
    },
    "211": {
        "file_id": 18,
        "content": "This code is a part of a decoding process in a deep learning model. It calculates the log probabilities of each sequence and stores them in a dictionary called \"sequences\". If the length of sequences reaches a certain threshold (beam_size), the loop breaks. Then, it creates two lists: tokens and sum_logprobs from the data stored in self.finished_sequences. Finally, it returns these two lists as output.\n\nThe LogitFilter class is an abstract base class for applying filtering or masking to logits during decoding. It has a method \"apply\" which takes logits and tokens as input but does not return anything. The SuppressBlank class inherits from LogitFilter and requires implementing the apply method according to specific requirements.",
        "type": "comment"
    },
    "212": {
        "file_id": 18,
        "content": "    def __init__(self, tokenizer: Tokenizer, sample_begin: int):\n        self.tokenizer = tokenizer\n        self.sample_begin = sample_begin\n    def apply(self, logits: Tensor, tokens: Tensor):\n        if tokens.shape[1] == self.sample_begin:\n            logits[:, self.tokenizer.encode(\" \") + [self.tokenizer.eot]] = -np.inf\nclass SuppressTokens(LogitFilter):\n    def __init__(self, suppress_tokens: Sequence[int]):\n        self.suppress_tokens = list(suppress_tokens)\n    def apply(self, logits: Tensor, tokens: Tensor):\n        logits[:, self.suppress_tokens] = -np.inf\nclass ApplyTimestampRules(LogitFilter):\n    def __init__(\n        self,\n        tokenizer: Tokenizer,\n        sample_begin: int,\n        max_initial_timestamp_index: Optional[int],\n    ):\n        self.tokenizer = tokenizer\n        self.sample_begin = sample_begin\n        self.max_initial_timestamp_index = max_initial_timestamp_index\n    def apply(self, logits: Tensor, tokens: Tensor):\n        # suppress <|notimestamps|> which is handled by without_timestamps",
        "type": "code",
        "location": "/whisper/decoding.py:424-453"
    },
    "213": {
        "file_id": 18,
        "content": "The code contains three classes, each representing a different method of filtering logits in a machine translation model. \"SuppressTokens\" applies a negative infinity penalty to specified token indices. \"ApplyTimestampRules\" suppresses <|notimestamps|> and sets negative penalties for certain tokens based on sample_begin and max_initial_timestamp_index. \"SuppressEmptyTokens\" sets a negative penalty for empty tokens.",
        "type": "comment"
    },
    "214": {
        "file_id": 18,
        "content": "        if self.tokenizer.no_timestamps is not None:\n            logits[:, self.tokenizer.no_timestamps] = -np.inf\n        # timestamps have to appear in pairs, except directly before EOT; mask logits accordingly\n        for k in range(tokens.shape[0]):\n            sampled_tokens = tokens[k, self.sample_begin :]\n            seq = [t for t in sampled_tokens.tolist()]\n            last_was_timestamp = (\n                len(seq) >= 1 and seq[-1] >= self.tokenizer.timestamp_begin\n            )\n            penultimate_was_timestamp = (\n                len(seq) < 2 or seq[-2] >= self.tokenizer.timestamp_begin\n            )\n            if last_was_timestamp:\n                if penultimate_was_timestamp:  # has to be non-timestamp\n                    logits[k, self.tokenizer.timestamp_begin :] = -np.inf\n                else:  # cannot be normal text tokens\n                    logits[k, : self.tokenizer.eot] = -np.inf\n            timestamps = sampled_tokens[\n                sampled_tokens.ge(self.tokenizer.timestamp_begin)",
        "type": "code",
        "location": "/whisper/decoding.py:454-475"
    },
    "215": {
        "file_id": 18,
        "content": "This code masks certain logits based on whether the preceding tokens are timestamps or not. If the preceding token is a timestamp, it sets corresponding logits to -inf, preventing them from being selected during sampling.",
        "type": "comment"
    },
    "216": {
        "file_id": 18,
        "content": "            ]\n            if timestamps.numel() > 0:\n                # timestamps shouldn't decrease; forbid timestamp tokens smaller than the last\n                # also force each segment to have a nonzero length, to prevent infinite looping\n                if last_was_timestamp and not penultimate_was_timestamp:\n                    timestamp_last = timestamps[-1]\n                else:\n                    timestamp_last = timestamps[-1] + 1\n                logits[k, self.tokenizer.timestamp_begin : timestamp_last] = -np.inf\n        if tokens.shape[1] == self.sample_begin:\n            # suppress generating non-timestamp tokens at the beginning\n            logits[:, : self.tokenizer.timestamp_begin] = -np.inf\n            # apply the `max_initial_timestamp` option\n            if self.max_initial_timestamp_index is not None:\n                last_allowed = (\n                    self.tokenizer.timestamp_begin + self.max_initial_timestamp_index\n                )\n                logits[:, last_allowed + 1 :] = -np.inf",
        "type": "code",
        "location": "/whisper/decoding.py:476-495"
    },
    "217": {
        "file_id": 18,
        "content": "This code is ensuring that the timestamps in the decoding process don't decrease and forcing each segment to have a non-zero length, preventing infinite looping. It also suppresses generating non-timestamp tokens at the beginning of the sequence and applies the `max_initial_timestamp` option if specified.",
        "type": "comment"
    },
    "218": {
        "file_id": 18,
        "content": "        # if sum of probability over timestamps is above any other token, sample timestamp\n        logprobs = F.log_softmax(logits.float(), dim=-1)\n        for k in range(tokens.shape[0]):\n            timestamp_logprob = logprobs[k, self.tokenizer.timestamp_begin :].logsumexp(\n                dim=-1\n            )\n            max_text_token_logprob = logprobs[k, : self.tokenizer.timestamp_begin].max()\n            if timestamp_logprob > max_text_token_logprob:\n                logits[k, : self.tokenizer.timestamp_begin] = -np.inf\nclass DecodingTask:\n    inference: Inference\n    sequence_ranker: SequenceRanker\n    decoder: TokenDecoder\n    logit_filters: List[LogitFilter]\n    def __init__(self, model: \"Whisper\", options: DecodingOptions):\n        self.model = model\n        language = options.language or \"en\"\n        tokenizer = get_tokenizer(\n            model.is_multilingual,\n            num_languages=model.num_languages,\n            language=language,\n            task=options.task,\n        )\n        self.tokenizer: Tokenizer = tokenizer",
        "type": "code",
        "location": "/whisper/decoding.py:497-524"
    },
    "219": {
        "file_id": 18,
        "content": "This code snippet is part of a machine learning model that performs speech-to-text decoding. It calculates the probability scores for each timestamp and token, then selects the timestamp with the highest log probability. The selected timestamp is used to sample the next token from the text tokens.",
        "type": "comment"
    },
    "220": {
        "file_id": 18,
        "content": "        self.options: DecodingOptions = self._verify_options(options)\n        self.n_group: int = options.beam_size or options.best_of or 1\n        self.n_ctx: int = model.dims.n_text_ctx\n        self.sample_len: int = options.sample_len or model.dims.n_text_ctx // 2\n        self.sot_sequence: Tuple[int] = tokenizer.sot_sequence\n        if self.options.without_timestamps:\n            self.sot_sequence = tokenizer.sot_sequence_including_notimestamps\n        self.initial_tokens: Tuple[int] = self._get_initial_tokens()\n        self.sample_begin: int = len(self.initial_tokens)\n        self.sot_index: int = self.initial_tokens.index(tokenizer.sot)\n        # inference: implements the forward pass through the decoder, including kv caching\n        self.inference = PyTorchInference(model, len(self.initial_tokens))\n        # sequence ranker: implements how to rank a group of sampled sequences\n        self.sequence_ranker = MaximumLikelihoodRanker(options.length_penalty)\n        # decoder: implements how to select the next tokens, given the autoregressive distribution",
        "type": "code",
        "location": "/whisper/decoding.py:525-545"
    },
    "221": {
        "file_id": 18,
        "content": "This code initializes various variables for decoding, such as beam size, maximum sample length, and initial tokens. It also creates instances of PyTorchInference and MaximumLikelihoodRanker classes, which are used for inference and sequence ranking respectively.",
        "type": "comment"
    },
    "222": {
        "file_id": 18,
        "content": "        if options.beam_size is not None:\n            self.decoder = BeamSearchDecoder(\n                options.beam_size, tokenizer.eot, self.inference, options.patience\n            )\n        else:\n            self.decoder = GreedyDecoder(options.temperature, tokenizer.eot)\n        # logit filters: applies various rules to suppress or penalize certain tokens\n        self.logit_filters = []\n        if self.options.suppress_blank:\n            self.logit_filters.append(SuppressBlank(self.tokenizer, self.sample_begin))\n        if self.options.suppress_tokens:\n            self.logit_filters.append(SuppressTokens(self._get_suppress_tokens()))\n        if not options.without_timestamps:\n            precision = CHUNK_LENGTH / model.dims.n_audio_ctx  # usually 0.02 seconds\n            max_initial_timestamp_index = None\n            if options.max_initial_timestamp:\n                max_initial_timestamp_index = round(\n                    self.options.max_initial_timestamp / precision\n                )\n            self.logit_filters.append(",
        "type": "code",
        "location": "/whisper/decoding.py:546-566"
    },
    "223": {
        "file_id": 18,
        "content": "This code initializes the decoder and logit filters for a model. The decoder is chosen based on the beam size option, with BeamSearchDecoder used if specified or GreedyDecoder otherwise. Logit filters are added based on options to suppress blank tokens or specific tokens. If timestamps are not disabled, a timestamp filter is also added.",
        "type": "comment"
    },
    "224": {
        "file_id": 18,
        "content": "                ApplyTimestampRules(\n                    tokenizer, self.sample_begin, max_initial_timestamp_index\n                )\n            )\n    def _verify_options(self, options: DecodingOptions) -> DecodingOptions:\n        if options.beam_size is not None and options.best_of is not None:\n            raise ValueError(\"beam_size and best_of can't be given together\")\n        if options.temperature == 0:\n            if options.best_of is not None:\n                raise ValueError(\"best_of with greedy sampling (T=0) is not compatible\")\n        if options.patience is not None and options.beam_size is None:\n            raise ValueError(\"patience requires beam_size to be given\")\n        if options.length_penalty is not None and not (\n            0 <= options.length_penalty <= 1\n        ):\n            raise ValueError(\"length_penalty (alpha) should be a value between 0 and 1\")\n        return options\n    def _get_initial_tokens(self) -> Tuple[int]:\n        tokens = list(self.sot_sequence)\n        if prefix := self.options.prefix:",
        "type": "code",
        "location": "/whisper/decoding.py:567-590"
    },
    "225": {
        "file_id": 18,
        "content": "This code defines a class with methods to initialize decoding options, verify them for compatibility, and get initial tokens. It also applies timestamp rules to tokens if necessary.",
        "type": "comment"
    },
    "226": {
        "file_id": 18,
        "content": "            prefix_tokens = (\n                self.tokenizer.encode(\" \" + prefix.strip())\n                if isinstance(prefix, str)\n                else prefix\n            )\n            if self.sample_len is not None:\n                max_prefix_len = self.n_ctx // 2 - self.sample_len\n                prefix_tokens = prefix_tokens[-max_prefix_len:]\n            tokens = tokens + prefix_tokens\n        if prompt := self.options.prompt:\n            prompt_tokens = (\n                self.tokenizer.encode(\" \" + prompt.strip())\n                if isinstance(prompt, str)\n                else prompt\n            )\n            tokens = (\n                [self.tokenizer.sot_prev]\n                + prompt_tokens[-(self.n_ctx // 2 - 1) :]\n                + tokens\n            )\n        return tuple(tokens)\n    def _get_suppress_tokens(self) -> Tuple[int]:\n        suppress_tokens = self.options.suppress_tokens\n        if isinstance(suppress_tokens, str):\n            suppress_tokens = [int(t) for t in suppress_tokens.split(\",\")]",
        "type": "code",
        "location": "/whisper/decoding.py:591-619"
    },
    "227": {
        "file_id": 18,
        "content": "Code snippet encodes prefix and prompt tokens, handles sample length, and defines suppress_tokens.",
        "type": "comment"
    },
    "228": {
        "file_id": 18,
        "content": "        if -1 in suppress_tokens:\n            suppress_tokens = [t for t in suppress_tokens if t >= 0]\n            suppress_tokens.extend(self.tokenizer.non_speech_tokens)\n        elif suppress_tokens is None or len(suppress_tokens) == 0:\n            suppress_tokens = []  # interpret empty string as an empty list\n        else:\n            assert isinstance(suppress_tokens, list), \"suppress_tokens must be a list\"\n        suppress_tokens.extend(\n            [\n                self.tokenizer.transcribe,\n                self.tokenizer.translate,\n                self.tokenizer.sot,\n                self.tokenizer.sot_prev,\n                self.tokenizer.sot_lm,\n            ]\n        )\n        if self.tokenizer.no_speech is not None:\n            # no-speech probability is collected separately\n            suppress_tokens.append(self.tokenizer.no_speech)\n        return tuple(sorted(set(suppress_tokens)))\n    def _get_audio_features(self, mel: Tensor):\n        if self.options.fp16:\n            mel = mel.half()\n        if mel.shape[-2:] == (",
        "type": "code",
        "location": "/whisper/decoding.py:621-648"
    },
    "229": {
        "file_id": 18,
        "content": "This code is responsible for managing a list of tokens that represent different aspects of audio processing, such as non-speech segments, transcribing, translating, and marking start of a segment. It ensures the list is in proper format and order, then extends it with specific tokens from the tokenizer, before possibly appending a no-speech probability if available.",
        "type": "comment"
    },
    "230": {
        "file_id": 18,
        "content": "            self.model.dims.n_audio_ctx,\n            self.model.dims.n_audio_state,\n        ):\n            # encoded audio features are given; skip audio encoding\n            audio_features = mel\n        else:\n            audio_features = self.model.encoder(mel)\n        if audio_features.dtype != (\n            torch.float16 if self.options.fp16 else torch.float32\n        ):\n            return TypeError(\n                f\"audio_features has an incorrect dtype: {audio_features.dtype}\"\n            )\n        return audio_features\n    def _detect_language(self, audio_features: Tensor, tokens: Tensor):\n        languages = [self.options.language] * audio_features.shape[0]\n        lang_probs = None\n        if self.options.language is None or self.options.task == \"lang_id\":\n            lang_tokens, lang_probs = self.model.detect_language(\n                audio_features, self.tokenizer\n            )\n            languages = [max(probs, key=probs.get) for probs in lang_probs]\n            if self.options.language is None:",
        "type": "code",
        "location": "/whisper/decoding.py:649-675"
    },
    "231": {
        "file_id": 18,
        "content": "This code defines two functions, `_get_audio_features` and `_detect_language`. \n\n`_get_audio_features` checks if the encoded audio features are given or not. If they are given, it skips audio encoding. Otherwise, it encodes the audio using `self.model.encoder(mel)`. It also checks if the audio features have the correct dtype (either float16 or float32).\n\n`_detect_language` either retrieves the specified language from options or detects languages using `self.model.detect_language(audio_features, self.tokenizer)` when no specific language is given or task is 'lang_id'. It assigns the detected language to `languages` and calculates the language probabilities (`lang_probs`) if necessary.",
        "type": "comment"
    },
    "232": {
        "file_id": 18,
        "content": "                tokens[:, self.sot_index + 1] = lang_tokens  # write language tokens\n        return languages, lang_probs\n    def _main_loop(self, audio_features: Tensor, tokens: Tensor):\n        n_batch = tokens.shape[0]\n        sum_logprobs: Tensor = torch.zeros(n_batch, device=audio_features.device)\n        no_speech_probs = [np.nan] * n_batch\n        try:\n            for i in range(self.sample_len):\n                logits = self.inference.logits(tokens, audio_features)\n                if (\n                    i == 0 and self.tokenizer.no_speech is not None\n                ):  # save no_speech_probs\n                    probs_at_sot = logits[:, self.sot_index].float().softmax(dim=-1)\n                    no_speech_probs = probs_at_sot[:, self.tokenizer.no_speech].tolist()\n                # now we need to consider the logits at the last token only\n                logits = logits[:, -1]\n                # apply the logit filters, e.g. for suppressing or applying penalty to\n                for logit_filter in self.logit_filters:",
        "type": "code",
        "location": "/whisper/decoding.py:676-699"
    },
    "233": {
        "file_id": 18,
        "content": "This code defines a function that performs inference on audio features and returns the languages and language probabilities. It also contains a loop that processes each chunk of audio features, calculates logits, applies logit filters, and keeps track of no_speech_probs if there is a specified no_speech token.",
        "type": "comment"
    },
    "234": {
        "file_id": 18,
        "content": "                    logit_filter.apply(logits, tokens)\n                # expand the tokens tensor with the selected next tokens\n                tokens, completed = self.decoder.update(tokens, logits, sum_logprobs)\n                if completed or tokens.shape[-1] > self.n_ctx:\n                    break\n        finally:\n            self.inference.cleanup_caching()\n        return tokens, sum_logprobs, no_speech_probs\n    @torch.no_grad()\n    def run(self, mel: Tensor) -> List[DecodingResult]:\n        self.decoder.reset()\n        tokenizer: Tokenizer = self.tokenizer\n        n_audio: int = mel.shape[0]\n        audio_features: Tensor = self._get_audio_features(mel)  # encoder forward pass\n        tokens: Tensor = torch.tensor([self.initial_tokens]).repeat(n_audio, 1)\n        # detect language if requested, overwriting the language token\n        languages, language_probs = self._detect_language(audio_features, tokens)\n        if self.options.task == \"lang_id\":\n            return [\n                DecodingResult(",
        "type": "code",
        "location": "/whisper/decoding.py:700-725"
    },
    "235": {
        "file_id": 18,
        "content": "The code is performing inference for text generation or language identification using a whisper model. It starts by resetting the decoder, tokenizing input audio, and getting audio features. The code then updates tokens based on selected next tokens and applies a logit filter. If a token has been completed or if there are too many tokens, it breaks the loop. Finally, it cleans up caching before returning the results.",
        "type": "comment"
    },
    "236": {
        "file_id": 18,
        "content": "                    audio_features=features, language=language, language_probs=probs\n                )\n                for features, language, probs in zip(\n                    audio_features, languages, language_probs\n                )\n            ]\n        # repeat text tensors by the group size, for beam search or best-of-n sampling\n        tokens = tokens.repeat_interleave(self.n_group, dim=0).to(audio_features.device)\n        # call the main sampling loop\n        tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n        # reshape the tensors to have (n_audio, n_group) as the first two dimensions\n        audio_features = audio_features[:: self.n_group]\n        no_speech_probs = no_speech_probs[:: self.n_group]\n        assert audio_features.shape[0] == len(no_speech_probs) == n_audio\n        tokens = tokens.reshape(n_audio, self.n_group, -1)\n        sum_logprobs = sum_logprobs.reshape(n_audio, self.n_group)\n        # get the final candidates for each group, and slice between the first sampled token and EOT",
        "type": "code",
        "location": "/whisper/decoding.py:726-747"
    },
    "237": {
        "file_id": 18,
        "content": "This code performs text-to-speech decoding by splitting the input audio into groups, repeating the text tensors for each group, then running a main sampling loop to generate speech tokens. The final candidates are extracted for each group and sliced up to the end of text (EOT) token.",
        "type": "comment"
    },
    "238": {
        "file_id": 18,
        "content": "        tokens, sum_logprobs = self.decoder.finalize(tokens, sum_logprobs)\n        tokens: List[List[Tensor]] = [\n            [t[self.sample_begin : (t == tokenizer.eot).nonzero()[0, 0]] for t in s]\n            for s in tokens\n        ]\n        # select the top-ranked sample in each group\n        selected = self.sequence_ranker.rank(tokens, sum_logprobs)\n        tokens: List[List[int]] = [t[i].tolist() for i, t in zip(selected, tokens)]\n        texts: List[str] = [tokenizer.decode(t).strip() for t in tokens]\n        sum_logprobs: List[float] = [lp[i] for i, lp in zip(selected, sum_logprobs)]\n        avg_logprobs: List[float] = [\n            lp / (len(t) + 1) for t, lp in zip(tokens, sum_logprobs)\n        ]\n        fields = (\n            texts,\n            languages,\n            tokens,\n            audio_features,\n            avg_logprobs,\n            no_speech_probs,\n        )\n        if len(set(map(len, fields))) != 1:\n            raise RuntimeError(f\"inconsistent result lengths: {list(map(len, fields))}\")\n        return [",
        "type": "code",
        "location": "/whisper/decoding.py:748-775"
    },
    "239": {
        "file_id": 18,
        "content": "This code snippet is part of a text decoding process. It selects the top-ranked sample from each group, calculates average log probabilities, and stores results in various formats (texts, languages, tokens, audio features). The code raises an error if result lengths are inconsistent.",
        "type": "comment"
    },
    "240": {
        "file_id": 18,
        "content": "            DecodingResult(\n                audio_features=features,\n                language=language,\n                tokens=tokens,\n                text=text,\n                avg_logprob=avg_logprob,\n                no_speech_prob=no_speech_prob,\n                temperature=self.options.temperature,\n                compression_ratio=compression_ratio(text),\n            )\n            for text, language, tokens, features, avg_logprob, no_speech_prob in zip(\n                *fields\n            )\n        ]\n@torch.no_grad()\ndef decode(\n    model: \"Whisper\",\n    mel: Tensor,\n    options: DecodingOptions = DecodingOptions(),\n    **kwargs,\n) -> Union[DecodingResult, List[DecodingResult]]:\n    \"\"\"\n    Performs decoding of 30-second audio segment(s), provided as Mel spectrogram(s).\n    Parameters\n    ----------\n    model: Whisper\n        the Whisper model instance\n    mel: torch.Tensor, shape = (80, 3000) or (*, 80, 3000)\n        A tensor containing the Mel spectrogram(s)\n    options: DecodingOptions\n        A dataclass that contains all necessary options for decoding 30-second segments",
        "type": "code",
        "location": "/whisper/decoding.py:776-811"
    },
    "241": {
        "file_id": 18,
        "content": "This code defines a function `decode` which takes in a Whisper model, Mel spectrogram(s), and optional decoding options. It performs the decoding of 30-second audio segment(s) by using the given model and mel spectrogram(s). The decoded result is returned as a DecodingResult object or a list of DecodingResult objects if multiple segments are provided.",
        "type": "comment"
    },
    "242": {
        "file_id": 18,
        "content": "    Returns\n    -------\n    result: Union[DecodingResult, List[DecodingResult]]\n        The result(s) of decoding contained in `DecodingResult` dataclass instance(s)\n    \"\"\"\n    if single := mel.ndim == 2:\n        mel = mel.unsqueeze(0)\n    if kwargs:\n        options = replace(options, **kwargs)\n    result = DecodingTask(model, options).run(mel)\n    return result[0] if single else result",
        "type": "code",
        "location": "/whisper/decoding.py:813-826"
    },
    "243": {
        "file_id": 18,
        "content": "This function takes a mel spectrogram and options as inputs, and uses a decoding task to perform speech recognition. If the mel spectrogram has 2 dimensions (single audio file), it is reshaped to have 3 dimensions (for batch processing). The options can be updated with additional keyword arguments. It then runs the decoding task with the model and options, returning the first result if a single audio file was input, or all results otherwise.",
        "type": "comment"
    },
    "244": {
        "file_id": 19,
        "content": "/whisper/model.py",
        "type": "filepath"
    },
    "245": {
        "file_id": 19,
        "content": "The code presents an audio-to-text conversion model using encoder-decoder architecture, with convolutional layers, attention blocks, and layer normalization for efficient processing.",
        "type": "summary"
    },
    "246": {
        "file_id": 19,
        "content": "import base64\nimport gzip\nfrom dataclasses import dataclass\nfrom typing import Dict, Iterable, Optional\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch import Tensor, nn\nfrom .decoding import decode as decode_function\nfrom .decoding import detect_language as detect_language_function\nfrom .transcribe import transcribe as transcribe_function\n@dataclass\nclass ModelDimensions:\n    n_mels: int\n    n_audio_ctx: int\n    n_audio_state: int\n    n_audio_head: int\n    n_audio_layer: int\n    n_vocab: int\n    n_text_ctx: int\n    n_text_state: int\n    n_text_head: int\n    n_text_layer: int\nclass LayerNorm(nn.LayerNorm):\n    def forward(self, x: Tensor) -> Tensor:\n        return super().forward(x.float()).type(x.dtype)\nclass Linear(nn.Linear):\n    def forward(self, x: Tensor) -> Tensor:\n        return F.linear(\n            x,\n            self.weight.to(x.dtype),\n            None if self.bias is None else self.bias.to(x.dtype),\n        )\nclass Conv1d(nn.Conv1d):\n    def _conv_forward(\n        self, x: Tensor, weight: Tensor, bias: Optional[Tensor]",
        "type": "code",
        "location": "/whisper/model.py:1-46"
    },
    "247": {
        "file_id": 19,
        "content": "The code imports necessary libraries and defines several classes and functions for a machine learning model. It includes LayerNorm, Linear, and Conv1d classes that are subclasses of torch.nn.Module with custom forward methods. ModelDimensions class is also defined to store the dimensions needed for the model's architecture. The code snippet seems to be part of a larger ML model implementation.",
        "type": "comment"
    },
    "248": {
        "file_id": 19,
        "content": "    ) -> Tensor:\n        return super()._conv_forward(\n            x, weight.to(x.dtype), None if bias is None else bias.to(x.dtype)\n        )\ndef sinusoids(length, channels, max_timescale=10000):\n    \"\"\"Returns sinusoids for positional embedding\"\"\"\n    assert channels % 2 == 0\n    log_timescale_increment = np.log(max_timescale) / (channels // 2 - 1)\n    inv_timescales = torch.exp(-log_timescale_increment * torch.arange(channels // 2))\n    scaled_time = torch.arange(length)[:, np.newaxis] * inv_timescales[np.newaxis, :]\n    return torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)], dim=1)\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, n_state: int, n_head: int):\n        super().__init__()\n        self.n_head = n_head\n        self.query = Linear(n_state, n_state)\n        self.key = Linear(n_state, n_state, bias=False)\n        self.value = Linear(n_state, n_state)\n        self.out = Linear(n_state, n_state)\n    def forward(\n        self,\n        x: Tensor,\n        xa: Optional[Tensor] = None,",
        "type": "code",
        "location": "/whisper/model.py:47-74"
    },
    "249": {
        "file_id": 19,
        "content": "Method \"_conv_forward\" is a convolution forward pass.\nFunction \"sinusoids\" returns sinusoids for positional embedding.\nClass \"MultiHeadAttention\" is a multi-head attention layer implementation.",
        "type": "comment"
    },
    "250": {
        "file_id": 19,
        "content": "        mask: Optional[Tensor] = None,\n        kv_cache: Optional[dict] = None,\n    ):\n        q = self.query(x)\n        if kv_cache is None or xa is None or self.key not in kv_cache:\n            # hooks, if installed (i.e. kv_cache is not None), will prepend the cached kv tensors;\n            # otherwise, perform key/value projections for self- or cross-attention as usual.\n            k = self.key(x if xa is None else xa)\n            v = self.value(x if xa is None else xa)\n        else:\n            # for cross-attention, calculate keys and values once and reuse in subsequent calls.\n            k = kv_cache[self.key]\n            v = kv_cache[self.value]\n        wv, qk = self.qkv_attention(q, k, v, mask)\n        return self.out(wv), qk\n    def qkv_attention(\n        self, q: Tensor, k: Tensor, v: Tensor, mask: Optional[Tensor] = None\n    ):\n        n_batch, n_ctx, n_state = q.shape\n        scale = (n_state // self.n_head) ** -0.25\n        q = q.view(*q.shape[:2], self.n_head, -1).permute(0, 2, 1, 3) * scale",
        "type": "code",
        "location": "/whisper/model.py:75-98"
    },
    "251": {
        "file_id": 19,
        "content": "This code defines a function that performs multi-head attention, either self or cross-attention. It takes input x and optionally pre-computed key and value tensors (kv_cache), and a mask for the attention mechanism. The function projects the input into query q and key k vectors, and then calculates the weighted sum of the value vector using the dot product between q and k, resulting in wv (weighted values) and qk (query keys).",
        "type": "comment"
    },
    "252": {
        "file_id": 19,
        "content": "        k = k.view(*k.shape[:2], self.n_head, -1).permute(0, 2, 3, 1) * scale\n        v = v.view(*v.shape[:2], self.n_head, -1).permute(0, 2, 1, 3)\n        qk = q @ k\n        if mask is not None:\n            qk = qk + mask[:n_ctx, :n_ctx]\n        qk = qk.float()\n        w = F.softmax(qk, dim=-1).to(q.dtype)\n        return (w @ v).permute(0, 2, 1, 3).flatten(start_dim=2), qk.detach()\nclass ResidualAttentionBlock(nn.Module):\n    def __init__(self, n_state: int, n_head: int, cross_attention: bool = False):\n        super().__init__()\n        self.attn = MultiHeadAttention(n_state, n_head)\n        self.attn_ln = LayerNorm(n_state)\n        self.cross_attn = (\n            MultiHeadAttention(n_state, n_head) if cross_attention else None\n        )\n        self.cross_attn_ln = LayerNorm(n_state) if cross_attention else None\n        n_mlp = n_state * 4\n        self.mlp = nn.Sequential(\n            Linear(n_state, n_mlp), nn.GELU(), Linear(n_mlp, n_state)\n        )\n        self.mlp_ln = LayerNorm(n_state)\n    def forward(",
        "type": "code",
        "location": "/whisper/model.py:99-129"
    },
    "253": {
        "file_id": 19,
        "content": "The code is defining a Residual Attention Block with MultiHeadAttention, layer normalization, and MLP. The block takes in an input of n_state size, splits it into n_head number of heads for attention, applies layer normalization before and after the attention mechanism, and after the MLP. It also has an optional cross-attention feature if specified during initialization.",
        "type": "comment"
    },
    "254": {
        "file_id": 19,
        "content": "        self,\n        x: Tensor,\n        xa: Optional[Tensor] = None,\n        mask: Optional[Tensor] = None,\n        kv_cache: Optional[dict] = None,\n    ):\n        x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n        if self.cross_attn:\n            x = x + self.cross_attn(self.cross_attn_ln(x), xa, kv_cache=kv_cache)[0]\n        x = x + self.mlp(self.mlp_ln(x))\n        return x\nclass AudioEncoder(nn.Module):\n    def __init__(\n        self, n_mels: int, n_ctx: int, n_state: int, n_head: int, n_layer: int\n    ):\n        super().__init__()\n        self.conv1 = Conv1d(n_mels, n_state, kernel_size=3, padding=1)\n        self.conv2 = Conv1d(n_state, n_state, kernel_size=3, stride=2, padding=1)\n        self.register_buffer(\"positional_embedding\", sinusoids(n_ctx, n_state))\n        self.blocks: Iterable[ResidualAttentionBlock] = nn.ModuleList(\n            [ResidualAttentionBlock(n_state, n_head) for _ in range(n_layer)]\n        )\n        self.ln_post = LayerNorm(n_state)\n    def forward(self, x: Tensor):",
        "type": "code",
        "location": "/whisper/model.py:130-157"
    },
    "255": {
        "file_id": 19,
        "content": "In the given code, a function is defined that applies multiple layers (attention blocks and MLP) to the input tensor 'x' and returns the output. The AudioEncoder class initializes the necessary modules and buffers for processing an audio signal.",
        "type": "comment"
    },
    "256": {
        "file_id": 19,
        "content": "        \"\"\"\n        x : torch.Tensor, shape = (batch_size, n_mels, n_ctx)\n            the mel spectrogram of the audio\n        \"\"\"\n        x = F.gelu(self.conv1(x))\n        x = F.gelu(self.conv2(x))\n        x = x.permute(0, 2, 1)\n        assert x.shape[1:] == self.positional_embedding.shape, \"incorrect audio shape\"\n        x = (x + self.positional_embedding).to(x.dtype)\n        for block in self.blocks:\n            x = block(x)\n        x = self.ln_post(x)\n        return x\nclass TextDecoder(nn.Module):\n    def __init__(\n        self, n_vocab: int, n_ctx: int, n_state: int, n_head: int, n_layer: int\n    ):\n        super().__init__()\n        self.token_embedding = nn.Embedding(n_vocab, n_state)\n        self.positional_embedding = nn.Parameter(torch.empty(n_ctx, n_state))\n        self.blocks: Iterable[ResidualAttentionBlock] = nn.ModuleList(\n            [\n                ResidualAttentionBlock(n_state, n_head, cross_attention=True)\n                for _ in range(n_layer)\n            ]\n        )\n        self.ln = LayerNorm(n_state)",
        "type": "code",
        "location": "/whisper/model.py:158-191"
    },
    "257": {
        "file_id": 19,
        "content": "The code defines a model for audio-to-text conversion. The `model.py` file contains a class called `WhisperModel`, which is an encoder-decoder architecture. It takes the mel spectrogram of the audio as input and outputs the corresponding text. The model consists of convolutional layers, positional embedding, residual attention blocks, and layer normalization. The `TextDecoder` class represents the decoder part of the model, which includes an embedding layer, positional embedding, residual attention blocks, and a layer normalization layer.",
        "type": "comment"
    },
    "258": {
        "file_id": 19,
        "content": "        mask = torch.empty(n_ctx, n_ctx).fill_(-np.inf).triu_(1)\n        self.register_buffer(\"mask\", mask, persistent=False)\n    def forward(self, x: Tensor, xa: Tensor, kv_cache: Optional[dict] = None):\n        \"\"\"\n        x : torch.LongTensor, shape = (batch_size, <= n_ctx)\n            the text tokens\n        xa : torch.Tensor, shape = (batch_size, n_audio_ctx, n_audio_state)\n            the encoded audio features to be attended on\n        \"\"\"\n        offset = next(iter(kv_cache.values())).shape[1] if kv_cache else 0\n        x = (\n            self.token_embedding(x)\n            + self.positional_embedding[offset : offset + x.shape[-1]]\n        )\n        x = x.to(xa.dtype)\n        for block in self.blocks:\n            x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n        x = self.ln(x)\n        logits = (\n            x @ torch.transpose(self.token_embedding.weight.to(x.dtype), 0, 1)\n        ).float()\n        return logits\nclass Whisper(nn.Module):\n    def __init__(self, dims: ModelDimensions):\n        super().__init__()",
        "type": "code",
        "location": "/whisper/model.py:193-223"
    },
    "259": {
        "file_id": 19,
        "content": "This code defines a Whisper model with an attention mechanism for processing both text and audio features. The `forward` method takes in text tokens, encoded audio features, and optionally a cache dictionary to perform forward pass. It applies token and positional embeddings, converts the input tensors to the same data type, iterates through the blocks of self-attention layers, applies layer normalization, and finally computes logits for predictions. The mask is used to ignore the upper triangular part of the attention matrix.",
        "type": "comment"
    },
    "260": {
        "file_id": 19,
        "content": "        self.dims = dims\n        self.encoder = AudioEncoder(\n            self.dims.n_mels,\n            self.dims.n_audio_ctx,\n            self.dims.n_audio_state,\n            self.dims.n_audio_head,\n            self.dims.n_audio_layer,\n        )\n        self.decoder = TextDecoder(\n            self.dims.n_vocab,\n            self.dims.n_text_ctx,\n            self.dims.n_text_state,\n            self.dims.n_text_head,\n            self.dims.n_text_layer,\n        )\n        # use the last half among the decoder layers for time alignment by default;\n        # to use a specific set of heads, see `set_alignment_heads()` below.\n        all_heads = torch.zeros(\n            self.dims.n_text_layer, self.dims.n_text_head, dtype=torch.bool\n        )\n        all_heads[self.dims.n_text_layer // 2 :] = True\n        self.register_buffer(\"alignment_heads\", all_heads.to_sparse(), persistent=False)\n    def set_alignment_heads(self, dump: bytes):\n        array = np.frombuffer(\n            gzip.decompress(base64.b85decode(dump)), dtype=bool",
        "type": "code",
        "location": "/whisper/model.py:224-249"
    },
    "261": {
        "file_id": 19,
        "content": "This code initializes a Whisper model with specified dimensions, sets up encoder and decoder layers, and registers a buffer for time alignment heads.",
        "type": "comment"
    },
    "262": {
        "file_id": 19,
        "content": "        ).copy()\n        mask = torch.from_numpy(array).reshape(\n            self.dims.n_text_layer, self.dims.n_text_head\n        )\n        self.register_buffer(\"alignment_heads\", mask.to_sparse(), persistent=False)\n    def embed_audio(self, mel: torch.Tensor):\n        return self.encoder(mel)\n    def logits(self, tokens: torch.Tensor, audio_features: torch.Tensor):\n        return self.decoder(tokens, audio_features)\n    def forward(\n        self, mel: torch.Tensor, tokens: torch.Tensor\n    ) -> Dict[str, torch.Tensor]:\n        return self.decoder(tokens, self.encoder(mel))\n    @property\n    def device(self):\n        return next(self.parameters()).device\n    @property\n    def is_multilingual(self):\n        return self.dims.n_vocab >= 51865\n    @property\n    def num_languages(self):\n        return self.dims.n_vocab - 51765 - int(self.is_multilingual)\n    def install_kv_cache_hooks(self, cache: Optional[dict] = None):\n        \"\"\"\n        The `MultiHeadAttention` module optionally accepts `kv_cache` which stores the key and value",
        "type": "code",
        "location": "/whisper/model.py:250-281"
    },
    "263": {
        "file_id": 19,
        "content": "This code defines a model for audio-text processing, likely for a task like speech recognition or translation. It includes an encoder and decoder network, as well as a MultiHeadAttention module with a mask for alignment between text and audio. The `embed_audio` method processes audio features using the encoder, while the `logits` method combines tokens and audio features for prediction. The `forward` function returns predictions using either tokens or audio features. The class also includes properties for device and language-related information, as well as a method to install cache hooks in the MultiHeadAttention module if needed.",
        "type": "comment"
    },
    "264": {
        "file_id": 19,
        "content": "        tensors calculated for the previous positions. This method returns a dictionary that stores\n        all caches, and the necessary hooks for the key and value projection modules that save the\n        intermediate tensors to be reused during later calculations.\n        Returns\n        -------\n        cache : Dict[nn.Module, torch.Tensor]\n            A dictionary object mapping the key/value projection modules to its cache\n        hooks : List[RemovableHandle]\n            List of PyTorch RemovableHandle objects to stop the hooks to be called\n        \"\"\"\n        cache = {**cache} if cache is not None else {}\n        hooks = []\n        def save_to_cache(module, _, output):\n            if module not in cache or output.shape[1] > self.dims.n_text_ctx:\n                # save as-is, for the first token or cross attention\n                cache[module] = output\n            else:\n                cache[module] = torch.cat([cache[module], output], dim=1).detach()\n            return cache[module]\n        def install_hooks(layer: nn.Module):",
        "type": "code",
        "location": "/whisper/model.py:282-304"
    },
    "265": {
        "file_id": 19,
        "content": "This code defines a method that calculates tensors for the previous positions and returns a dictionary storing caches of key/value projection modules. It also provides hooks to save intermediate tensors for later calculations.",
        "type": "comment"
    },
    "266": {
        "file_id": 19,
        "content": "            if isinstance(layer, MultiHeadAttention):\n                hooks.append(layer.key.register_forward_hook(save_to_cache))\n                hooks.append(layer.value.register_forward_hook(save_to_cache))\n        self.decoder.apply(install_hooks)\n        return cache, hooks\n    detect_language = detect_language_function\n    transcribe = transcribe_function\n    decode = decode_function",
        "type": "code",
        "location": "/whisper/model.py:305-314"
    },
    "267": {
        "file_id": 19,
        "content": "Checks if the layer is a MultiHeadAttention, then registers forward hooks on key and value of that layer. Applies hooks to the decoder, returns cache and hooks.",
        "type": "comment"
    },
    "268": {
        "file_id": 20,
        "content": "/whisper/normalizers/__init__.py",
        "type": "filepath"
    },
    "269": {
        "file_id": 20,
        "content": "Importing BasicTextNormalizer and EnglishTextNormalizer from respective modules.",
        "type": "summary"
    },
    "270": {
        "file_id": 20,
        "content": "from .basic import BasicTextNormalizer as BasicTextNormalizer\nfrom .english import EnglishTextNormalizer as EnglishTextNormalizer",
        "type": "code",
        "location": "/whisper/normalizers/__init__.py:1-2"
    },
    "271": {
        "file_id": 20,
        "content": "Importing BasicTextNormalizer and EnglishTextNormalizer from respective modules.",
        "type": "comment"
    },
    "272": {
        "file_id": 21,
        "content": "/whisper/normalizers/basic.py",
        "type": "filepath"
    },
    "273": {
        "file_id": 21,
        "content": "The code normalizes text by removing symbols, punctuation, and diacritics using NFKD normalization. It keeps specified characters and splits letters if instructed while also dropping words within brackets or parentheses.",
        "type": "summary"
    },
    "274": {
        "file_id": 21,
        "content": "import re\nimport unicodedata\nimport regex\n# non-ASCII letters that are not separated by \"NFKD\" normalization\nADDITIONAL_DIACRITICS = {\n    \"œ\": \"oe\",\n    \"Œ\": \"OE\",\n    \"ø\": \"o\",\n    \"Ø\": \"O\",\n    \"æ\": \"ae\",\n    \"Æ\": \"AE\",\n    \"ß\": \"ss\",\n    \"ẞ\": \"SS\",\n    \"đ\": \"d\",\n    \"Đ\": \"D\",\n    \"ð\": \"d\",\n    \"Ð\": \"D\",\n    \"þ\": \"th\",\n    \"Þ\": \"th\",\n    \"ł\": \"l\",\n    \"Ł\": \"L\",\n}\ndef remove_symbols_and_diacritics(s: str, keep=\"\"):\n    \"\"\"\n    Replace any other markers, symbols, and punctuations with a space,\n    and drop any diacritics (category 'Mn' and some manual mappings)\n    \"\"\"\n    return \"\".join(\n        c\n        if c in keep\n        else ADDITIONAL_DIACRITICS[c]\n        if c in ADDITIONAL_DIACRITICS\n        else \"\"\n        if unicodedata.category(c) == \"Mn\"\n        else \" \"\n        if unicodedata.category(c)[0] in \"MSP\"\n        else c\n        for c in unicodedata.normalize(\"NFKD\", s)\n    )\ndef remove_symbols(s: str):\n    \"\"\"\n    Replace any other markers, symbols, punctuations with a space, keeping diacritics\n    \"\"\"\n    return \"\".join(",
        "type": "code",
        "location": "/whisper/normalizers/basic.py:1-50"
    },
    "275": {
        "file_id": 21,
        "content": "This code defines functions to remove symbols, punctuations, and diacritics from a string. It first normalizes the input string using \"NFKD\" normalization, then replaces non-ASCII letters with their ASCII equivalents, keeps specified characters, and removes other markers, symbols, and punctuations by replacing them with spaces. The \"remove_symbols_and_diacritics\" function also drops diacritics in addition to the symbol processing.",
        "type": "comment"
    },
    "276": {
        "file_id": 21,
        "content": "        \" \" if unicodedata.category(c)[0] in \"MSP\" else c\n        for c in unicodedata.normalize(\"NFKC\", s)\n    )\nclass BasicTextNormalizer:\n    def __init__(self, remove_diacritics: bool = False, split_letters: bool = False):\n        self.clean = (\n            remove_symbols_and_diacritics if remove_diacritics else remove_symbols\n        )\n        self.split_letters = split_letters\n    def __call__(self, s: str):\n        s = s.lower()\n        s = re.sub(r\"[<\\[][^>\\]]*[>\\]]\", \"\", s)  # remove words between brackets\n        s = re.sub(r\"\\(([^)]+?)\\)\", \"\", s)  # remove words between parenthesis\n        s = self.clean(s).lower()\n        if self.split_letters:\n            s = \" \".join(regex.findall(r\"\\X\", s, regex.U))\n        s = re.sub(\n            r\"\\s+\", \" \", s\n        )  # replace any successive whitespace characters with a space\n        return s",
        "type": "code",
        "location": "/whisper/normalizers/basic.py:51-76"
    },
    "277": {
        "file_id": 21,
        "content": "This code is a text normalizer that removes symbols, diacritics, and splits letters if specified. It also removes words between brackets and parentheses, and replaces successive whitespace characters with a single space.",
        "type": "comment"
    },
    "278": {
        "file_id": 22,
        "content": "/whisper/normalizers/english.py",
        "type": "filepath"
    },
    "279": {
        "file_id": 22,
        "content": "The EnglishNumberNormalizer class handles spelled-out numbers and applies normalization functions for conversions, while the code contains two classes: \"EnglishSpellingNormalizer\" and \"EnglishTextNormalizer,\" which apply regular expressions to standardize spellings and adjust whitespace in text.",
        "type": "summary"
    },
    "280": {
        "file_id": 22,
        "content": "import json\nimport os\nimport re\nfrom fractions import Fraction\nfrom typing import Iterator, List, Match, Optional, Union\nfrom more_itertools import windowed\nfrom .basic import remove_symbols_and_diacritics\nclass EnglishNumberNormalizer:\n    \"\"\"\n    Convert any spelled-out numbers into arabic numbers, while handling:\n    - remove any commas\n    - keep the suffixes such as: `1960s`, `274th`, `32nd`, etc.\n    - spell out currency symbols after the number. e.g. `$20 million` -> `20000000 dollars`\n    - spell out `one` and `ones`\n    - interpret successive single-digit numbers as nominal: `one oh one` -> `101`\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self.zeros = {\"o\", \"oh\", \"zero\"}\n        self.ones = {\n            name: i\n            for i, name in enumerate(\n                [\n                    \"one\",\n                    \"two\",\n                    \"three\",\n                    \"four\",\n                    \"five\",\n                    \"six\",\n                    \"seven\",\n                    \"eight\",",
        "type": "code",
        "location": "/whisper/normalizers/english.py:1-38"
    },
    "281": {
        "file_id": 22,
        "content": "EnglishNumberNormalizer class definition with properties for handling various spelled-out numbers and currency symbols.",
        "type": "comment"
    },
    "282": {
        "file_id": 22,
        "content": "                    \"nine\",\n                    \"ten\",\n                    \"eleven\",\n                    \"twelve\",\n                    \"thirteen\",\n                    \"fourteen\",\n                    \"fifteen\",\n                    \"sixteen\",\n                    \"seventeen\",\n                    \"eighteen\",\n                    \"nineteen\",\n                ],\n                start=1,\n            )\n        }\n        self.ones_plural = {\n            \"sixes\" if name == \"six\" else name + \"s\": (value, \"s\")\n            for name, value in self.ones.items()\n        }\n        self.ones_ordinal = {\n            \"zeroth\": (0, \"th\"),\n            \"first\": (1, \"st\"),\n            \"second\": (2, \"nd\"),\n            \"third\": (3, \"rd\"),\n            \"fifth\": (5, \"th\"),\n            \"twelfth\": (12, \"th\"),\n            **{\n                name + (\"h\" if name.endswith(\"t\") else \"th\"): (value, \"th\")\n                for name, value in self.ones.items()\n                if value > 3 and value != 5 and value != 12\n            },\n        }\n        self.ones_suffixed = {**self.ones_plural, **self.ones_ordinal}",
        "type": "code",
        "location": "/whisper/normalizers/english.py:39-71"
    },
    "283": {
        "file_id": 22,
        "content": "This code is defining various mappings for numbers 1-20, including plural form, ordinal form, and suffixed forms. It handles exceptions for specific numbers like \"twelfth\" with a suffix \"th\". The final result is a dictionary of these different number variations called \"ones_suffixed\".",
        "type": "comment"
    },
    "284": {
        "file_id": 22,
        "content": "        self.tens = {\n            \"twenty\": 20,\n            \"thirty\": 30,\n            \"forty\": 40,\n            \"fifty\": 50,\n            \"sixty\": 60,\n            \"seventy\": 70,\n            \"eighty\": 80,\n            \"ninety\": 90,\n        }\n        self.tens_plural = {\n            name.replace(\"y\", \"ies\"): (value, \"s\") for name, value in self.tens.items()\n        }\n        self.tens_ordinal = {\n            name.replace(\"y\", \"ieth\"): (value, \"th\")\n            for name, value in self.tens.items()\n        }\n        self.tens_suffixed = {**self.tens_plural, **self.tens_ordinal}\n        self.multipliers = {\n            \"hundred\": 100,\n            \"thousand\": 1_000,\n            \"million\": 1_000_000,\n            \"billion\": 1_000_000_000,\n            \"trillion\": 1_000_000_000_000,\n            \"quadrillion\": 1_000_000_000_000_000,\n            \"quintillion\": 1_000_000_000_000_000_000,\n            \"sextillion\": 1_000_000_000_000_000_000_000,\n            \"septillion\": 1_000_000_000_000_000_000_000_000,\n            \"octillion\": 1_000_000_000_000_000_000_000_000_000,",
        "type": "code",
        "location": "/whisper/normalizers/english.py:73-102"
    },
    "285": {
        "file_id": 22,
        "content": "The code defines various number normalizations for English language. It includes tens, tens plural, tens ordinal and multipliers as dictionaries to handle different number representations in text.",
        "type": "comment"
    },
    "286": {
        "file_id": 22,
        "content": "            \"nonillion\": 1_000_000_000_000_000_000_000_000_000_000,\n            \"decillion\": 1_000_000_000_000_000_000_000_000_000_000_000,\n        }\n        self.multipliers_plural = {\n            name + \"s\": (value, \"s\") for name, value in self.multipliers.items()\n        }\n        self.multipliers_ordinal = {\n            name + \"th\": (value, \"th\") for name, value in self.multipliers.items()\n        }\n        self.multipliers_suffixed = {\n            **self.multipliers_plural,\n            **self.multipliers_ordinal,\n        }\n        self.decimals = {*self.ones, *self.tens, *self.zeros}\n        self.preceding_prefixers = {\n            \"minus\": \"-\",\n            \"negative\": \"-\",\n            \"plus\": \"+\",\n            \"positive\": \"+\",\n        }\n        self.following_prefixers = {\n            \"pound\": \"£\",\n            \"pounds\": \"£\",\n            \"euro\": \"€\",\n            \"euros\": \"€\",\n            \"dollar\": \"$\",\n            \"dollars\": \"$\",\n            \"cent\": \"¢\",\n            \"cents\": \"¢\",\n        }\n        self.prefixes = set(",
        "type": "code",
        "location": "/whisper/normalizers/english.py:103-134"
    },
    "287": {
        "file_id": 22,
        "content": "This code defines various prefixes and multipliers for English numbers. It creates dictionaries for plural, ordinal, and suffixed forms of the numbers. The code also includes a dictionary for decimal values and separate dictionaries for preceding and following prefixes like currency symbols. Finally, it defines a set of prefixes used in the code.",
        "type": "comment"
    },
    "288": {
        "file_id": 22,
        "content": "            list(self.preceding_prefixers.values())\n            + list(self.following_prefixers.values())\n        )\n        self.suffixers = {\n            \"per\": {\"cent\": \"%\"},\n            \"percent\": \"%\",\n        }\n        self.specials = {\"and\", \"double\", \"triple\", \"point\"}\n        self.words = set(\n            [\n                key\n                for mapping in [\n                    self.zeros,\n                    self.ones,\n                    self.ones_suffixed,\n                    self.tens,\n                    self.tens_suffixed,\n                    self.multipliers,\n                    self.multipliers_suffixed,\n                    self.preceding_prefixers,\n                    self.following_prefixers,\n                    self.suffixers,\n                    self.specials,\n                ]\n                for key in mapping\n            ]\n        )\n        self.literal_words = {\"one\", \"ones\"}\n    def process_words(self, words: List[str]) -> Iterator[str]:\n        prefix: Optional[str] = None\n        value: Optional[Union[str, int]] = None",
        "type": "code",
        "location": "/whisper/normalizers/english.py:135-167"
    },
    "289": {
        "file_id": 22,
        "content": "The code defines a class with various mappings and sets of words. It initializes instance variables for preceding and following prefixers, suffixes, special words, and literal words. The process_words method takes a list of words as input and returns an iterator of processed strings.",
        "type": "comment"
    },
    "290": {
        "file_id": 22,
        "content": "        skip = False\n        def to_fraction(s: str):\n            try:\n                return Fraction(s)\n            except ValueError:\n                return None\n        def output(result: Union[str, int]):\n            nonlocal prefix, value\n            result = str(result)\n            if prefix is not None:\n                result = prefix + result\n            value = None\n            prefix = None\n            return result\n        if len(words) == 0:\n            return\n        for prev, current, next in windowed([None] + words + [None], 3):\n            if skip:\n                skip = False\n                continue\n            next_is_numeric = next is not None and re.match(r\"^\\d+(\\.\\d+)?$\", next)\n            has_prefix = current[0] in self.prefixes\n            current_without_prefix = current[1:] if has_prefix else current\n            if re.match(r\"^\\d+(\\.\\d+)?$\", current_without_prefix):\n                # arabic numbers (potentially with signs and fractions)\n                f = to_fraction(current_without_prefix)",
        "type": "code",
        "location": "/whisper/normalizers/english.py:168-198"
    },
    "291": {
        "file_id": 22,
        "content": "This code defines functions for normalizing English text. It checks if the current word is a number and handles fractions, skips over words marked as \"skip\", and processes words with or without prefixes.",
        "type": "comment"
    },
    "292": {
        "file_id": 22,
        "content": "                assert f is not None\n                if value is not None:\n                    if isinstance(value, str) and value.endswith(\".\"):\n                        # concatenate decimals / ip address components\n                        value = str(value) + str(current)\n                        continue\n                    else:\n                        yield output(value)\n                prefix = current[0] if has_prefix else prefix\n                if f.denominator == 1:\n                    value = f.numerator  # store integers as int\n                else:\n                    value = current_without_prefix\n            elif current not in self.words:\n                # non-numeric words\n                if value is not None:\n                    yield output(value)\n                yield output(current)\n            elif current in self.zeros:\n                value = str(value or \"\") + \"0\"\n            elif current in self.ones:\n                ones = self.ones[current]\n                if value is None:\n                    value = ones",
        "type": "code",
        "location": "/whisper/normalizers/english.py:199-224"
    },
    "293": {
        "file_id": 22,
        "content": "This code is handling various cases of number normalization. It checks if the value is a string ending with \".\", concatenates decimals/IP address components, handles numeric and non-numeric words, zeros, and ones.",
        "type": "comment"
    },
    "294": {
        "file_id": 22,
        "content": "                elif isinstance(value, str) or prev in self.ones:\n                    if (\n                        prev in self.tens and ones < 10\n                    ):  # replace the last zero with the digit\n                        assert value[-1] == \"0\"\n                        value = value[:-1] + str(ones)\n                    else:\n                        value = str(value) + str(ones)\n                elif ones < 10:\n                    if value % 10 == 0:\n                        value += ones\n                    else:\n                        value = str(value) + str(ones)\n                else:  # eleven to nineteen\n                    if value % 100 == 0:\n                        value += ones\n                    else:\n                        value = str(value) + str(ones)\n            elif current in self.ones_suffixed:\n                # ordinal or cardinal; yield the number right away\n                ones, suffix = self.ones_suffixed[current]\n                if value is None:\n                    yield output(str(ones) + suffix)",
        "type": "code",
        "location": "/whisper/normalizers/english.py:225-247"
    },
    "295": {
        "file_id": 22,
        "content": "This code snippet is part of a normalizer function for the English language. It handles different cases to convert numbers into spoken words, including handling tens and ones place values, as well as cardinal or ordinal numbers. If the previous number had a \"0\" at the end and the one's digit is less than 10, it replaces the last zero with the digit. If the one's digit is less than 10 but the current value is not ending in a zero, it concatenates the string representation of the current value and the ones. If the one's digit is 11 to 19, it appends the ones digit if the current value is divisible by 100 or simply concatenates the string representation of the current value and the ones. If the current number is in the 'ones_suffixed' list, it yields the number with the appropriate suffix.",
        "type": "comment"
    },
    "296": {
        "file_id": 22,
        "content": "                elif isinstance(value, str) or prev in self.ones:\n                    if prev in self.tens and ones < 10:\n                        assert value[-1] == \"0\"\n                        yield output(value[:-1] + str(ones) + suffix)\n                    else:\n                        yield output(str(value) + str(ones) + suffix)\n                elif ones < 10:\n                    if value % 10 == 0:\n                        yield output(str(value + ones) + suffix)\n                    else:\n                        yield output(str(value) + str(ones) + suffix)\n                else:  # eleven to nineteen\n                    if value % 100 == 0:\n                        yield output(str(value + ones) + suffix)\n                    else:\n                        yield output(str(value) + str(ones) + suffix)\n                value = None\n            elif current in self.tens:\n                tens = self.tens[current]\n                if value is None:\n                    value = tens\n                elif isinstance(value, str):",
        "type": "code",
        "location": "/whisper/normalizers/english.py:248-269"
    },
    "297": {
        "file_id": 22,
        "content": "This code snippet is handling the conversion of numbers to words in English. It checks if the number is a multiple of 10, and handles values from 11 to 19, 20 to 29, etc., separately. It also deals with cases where the value is a string or a single digit number (ones place).",
        "type": "comment"
    },
    "298": {
        "file_id": 22,
        "content": "                    value = str(value) + str(tens)\n                else:\n                    if value % 100 == 0:\n                        value += tens\n                    else:\n                        value = str(value) + str(tens)\n            elif current in self.tens_suffixed:\n                # ordinal or cardinal; yield the number right away\n                tens, suffix = self.tens_suffixed[current]\n                if value is None:\n                    yield output(str(tens) + suffix)\n                elif isinstance(value, str):\n                    yield output(str(value) + str(tens) + suffix)\n                else:\n                    if value % 100 == 0:\n                        yield output(str(value + tens) + suffix)\n                    else:\n                        yield output(str(value) + str(tens) + suffix)\n            elif current in self.multipliers:\n                multiplier = self.multipliers[current]\n                if value is None:\n                    value = multiplier\n                elif isinstance(value, str) or value == 0:",
        "type": "code",
        "location": "/whisper/normalizers/english.py:270-292"
    },
    "299": {
        "file_id": 22,
        "content": "This code is part of a normalizer for the English language. It handles converting numbers into words based on their position and value. The code checks if the number has a specific digit and adds the corresponding suffix or multiplies by a specific factor depending on the context.",
        "type": "comment"
    }
}