{
    "summary": "The code initializes a LibriSpeech dataset, installs Whisper and its dependencies, loads the test-clean split, performs inference for transcription, stores results in a pandas DataFrame, cleans up text, calculates WER, and prints it out.",
    "details": [
        {
            "comment": "Installation of Whisper and loading the LibriSpeech dataset.\n- Installs required packages for using Whisper models.\n- Loads test-clean split of LibriSpeech corpus using torchaudio.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/notebooks/LibriSpeech.py\":0-48",
            "content": "#!/usr/bin/env python\n# coding: utf-8\n# # Installing Whisper\n# \n# The commands below will install the Python packages needed to use Whisper models and evaluate the transcription results.\n# In[1]:\nget_ipython().system(' pip install git+https://github.com/openai/whisper.git')\nget_ipython().system(' pip install jiwer')\n# # Loading the LibriSpeech dataset\n# \n# The following will load the test-clean split of the LibriSpeech corpus using torchaudio.\n# In[2]:\nimport os\nimport numpy as np\ntry:\n    import tensorflow  # required in Colab to avoid protobuf compatibility issues\nexcept ImportError:\n    pass\nimport torch\nimport pandas as pd\nimport whisper\nimport torchaudio\nfrom tqdm.notebook import tqdm\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# In[3]:\nclass LibriSpeech(torch.utils.data.Dataset):\n    \"\"\"\n    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n    It will drop the last few seconds of a very small portion of the utterances.\n    \"\"\"\n    def __init__(self, split=\"test-clean\", device=DEVICE):"
        },
        {
            "comment": "This code initializes a LibriSpeech dataset, loads a Whisper model, and then runs inference on the dataset to perform transcription.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/notebooks/LibriSpeech.py\":49-92",
            "content": "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n            root=os.path.expanduser(\"~/.cache\"),\n            url=split,\n            download=True,\n        )\n        self.device = device\n    def __len__(self):\n        return len(self.dataset)\n    def __getitem__(self, item):\n        audio, sample_rate, text, _, _, _ = self.dataset[item]\n        assert sample_rate == 16000\n        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n        mel = whisper.log_mel_spectrogram(audio)\n        return (mel, text)\n# In[4]:\ndataset = LibriSpeech(\"test-clean\")\nloader = torch.utils.data.DataLoader(dataset, batch_size=16)\n# # Running inference on the dataset using a base Whisper model\n# \n# The following will take a few minutes to transcribe all utterances in the dataset.\n# In[5]:\nmodel = whisper.load_model(\"base.en\")\nprint(\n    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n)\n# In[6]:\n# predict without timestamps for short-form transcription"
        },
        {
            "comment": "This code uses the Whisper library to transcribe audio data (in mel spectrogram format) and stores the transcriptions and corresponding references in a pandas DataFrame. It then applies an English text normalizer to clean up the transcriptions, calculates the Word Error Rate (WER), and prints it out.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/notebooks/LibriSpeech.py\":93-141",
            "content": "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)\n# In[7]:\nhypotheses = []\nreferences = []\nfor mels, texts in tqdm(loader):\n    results = model.decode(mels, options)\n    hypotheses.extend([result.text for result in results])\n    references.extend(texts)\n# In[8]:\ndata = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\ndata\n# # Calculating the word error rate\n# \n# Now, we use our English normalizer implementation to standardize the transcription and calculate the WER.\n# In[9]:\nimport jiwer\nfrom whisper.normalizers import EnglishTextNormalizer\nnormalizer = EnglishTextNormalizer()\n# In[10]:\ndata[\"hypothesis_clean\"] = [normalizer(text) for text in data[\"hypothesis\"]]\ndata[\"reference_clean\"] = [normalizer(text) for text in data[\"reference\"]]\ndata\n# In[11]:\nwer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\nprint(f\"WER: {wer * 100:.2f} %\")"
        }
    ]
}