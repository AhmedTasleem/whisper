{
    "summary": "The code includes two functions: a dynamic time warping algorithm using Triton's parallel computing and a median filter implemented with CUDA, performing convolution operations on input tensors.",
    "details": [
        {
            "comment": "This code defines a function `dtw_kernel` that uses the Triton programming language to implement dynamic time warping (DTW) algorithm. It takes cost, trace, x arrays as input and calculates the DTW distance between two sequences. The function uses triton's parallel computing capabilities to optimize performance.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/triton_ops.py\":0-36",
            "content": "from functools import lru_cache\nimport numpy as np\nimport torch\ntry:\n    import triton\n    import triton.language as tl\nexcept ImportError:\n    raise RuntimeError(\"triton import failed; try `pip install --pre triton`\")\n@triton.jit\ndef dtw_kernel(\n    cost, trace, x, x_stride, cost_stride, trace_stride, N, M, BLOCK_SIZE: tl.constexpr\n):\n    offsets = tl.arange(0, BLOCK_SIZE)\n    mask = offsets < M\n    for k in range(1, N + M + 1):  # k = i + j\n        tl.debug_barrier()\n        p0 = cost + (k - 1) * cost_stride\n        p1 = cost + k * cost_stride\n        p2 = cost + k * cost_stride + 1\n        c0 = tl.load(p0 + offsets, mask=mask)\n        c1 = tl.load(p1 + offsets, mask=mask)\n        c2 = tl.load(p2 + offsets, mask=mask)\n        x_row = tl.load(x + (k - 1) * x_stride + offsets, mask=mask, other=0)\n        cost_row = x_row + tl.minimum(tl.minimum(c0, c1), c2)\n        cost_ptr = cost + (k + 1) * cost_stride + 1\n        tl.store(cost_ptr + offsets, cost_row, mask=mask)\n        trace_ptr = trace + (k + 1) * trace_stride + 1"
        },
        {
            "comment": "This code is implementing a median filter using Triton library. It loads pixel values from an input image, sorts them, and stores the middle value back into the image. The function is JIT compiled for performance.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/triton_ops.py\":37-67",
            "content": "        tl.store(trace_ptr + offsets, 2, mask=mask & (c2 <= c0) & (c2 <= c1))\n        tl.store(trace_ptr + offsets, 1, mask=mask & (c1 <= c0) & (c1 <= c2))\n        tl.store(trace_ptr + offsets, 0, mask=mask & (c0 <= c1) & (c0 <= c2))\n@lru_cache(maxsize=None)\ndef median_kernel(filter_width: int):\n    @triton.jit\n    def kernel(\n        y, x, x_stride, y_stride, BLOCK_SIZE: tl.constexpr\n    ):  # x.shape[-1] == filter_width\n        row_idx = tl.program_id(0)\n        offsets = tl.arange(0, BLOCK_SIZE)\n        mask = offsets < y_stride\n        x_ptr = x + row_idx * x_stride  # noqa: F841\n        y_ptr = y + row_idx * y_stride\n        LOAD_ALL_ROWS_HERE  # noqa: F821\n        BUBBLESORT_HERE  # noqa: F821\n        tl.store(y_ptr + offsets, MIDDLE_ROW_HERE, mask=mask)  # noqa: F821\n    kernel = triton.JITFunction(kernel.fn)\n    kernel.src = kernel.src.replace(\n        \"    LOAD_ALL_ROWS_HERE\",\n        \"\\n\".join(\n            [\n                f\"    row{i} = tl.load(x_ptr + offsets + {i}, mask=mask)\"\n                for i in range(filter_width)"
        },
        {
            "comment": "This code is implementing a median filter with CUDA for a given tensor. It replaces the specified sections of the kernel source code to perform a bubblesort on rows of the tensor, then updates each row with its corresponding median value. The filter_width determines the size of the median filter applied along the last dimension of the input tensor.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/triton_ops.py\":68-98",
            "content": "            ]\n        ),\n    )\n    kernel.src = kernel.src.replace(\n        \"    BUBBLESORT_HERE\",\n        \"\\n\\n\".join(\n            [\n                \"\\n\\n\".join(\n                    [\n                        \"\\n\".join(\n                            [\n                                f\"    smaller = tl.where(row{j} < row{j + 1}, row{j}, row{j + 1})\",\n                                f\"    larger = tl.where(row{j} > row{j + 1}, row{j}, row{j + 1})\",\n                                f\"    row{j} = smaller\",\n                                f\"    row{j + 1} = larger\",\n                            ]\n                        )\n                        for j in range(filter_width - i - 1)\n                    ]\n                )\n                for i in range(filter_width // 2 + 1)\n            ]\n        ),\n    )\n    kernel.src = kernel.src.replace(\"MIDDLE_ROW_HERE\", f\"row{filter_width // 2}\")\n    return kernel\ndef median_filter_cuda(x: torch.Tensor, filter_width: int):\n    \"\"\"Apply a median filter of given width along the last dimension of x\"\"\""
        },
        {
            "comment": "This code is performing a convolution operation on an input tensor 'x' using a kernel of size 'filter_width'. The result is stored in tensor 'y', and the BLOCK_SIZE is determined based on the stride of 'x'.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/triton_ops.py\":99-108",
            "content": "    slices = x.contiguous().unfold(-1, filter_width, 1)\n    grid = np.prod(slices.shape[:-2])\n    kernel = median_kernel(filter_width)\n    y = torch.empty_like(slices[..., 0])\n    BLOCK_SIZE = 1 << (y.stride(-2) - 1).bit_length()\n    kernel[(grid,)](y, x, x.stride(-2), y.stride(-2), BLOCK_SIZE=BLOCK_SIZE)\n    return y"
        }
    ]
}