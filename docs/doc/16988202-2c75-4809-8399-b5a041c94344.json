{
    "summary": "The Whisper library imports necessary libraries and defines functions for downloading pre-trained models, verifying their integrity, and providing a list of available models to load.",
    "details": [
        {
            "comment": "Storage location: \"whisper/__init__.py\":0-21\nCode: This code is importing necessary libraries, defining types and functions related to Whisper model, and storing pre-trained models' URLs.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/__init__.py\":0-21",
            "content": "import hashlib\nimport io\nimport os\nimport urllib\nimport warnings\nfrom typing import List, Optional, Union\nimport torch\nfrom tqdm import tqdm\nfrom .audio import load_audio, log_mel_spectrogram, pad_or_trim\nfrom .decoding import DecodingOptions, DecodingResult, decode, detect_language\nfrom .model import ModelDimensions, Whisper\nfrom .transcribe import transcribe\nfrom .version import __version__\n_MODELS = {\n    \"tiny.en\": \"https://openaipublic.azureedge.net/main/whisper/models/d3dd57d32accea0b295c96e26691aa14d8822fac7d9d27d5dc00b4ca2826dd03/tiny.en.pt\",\n    \"tiny\": \"https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt\",\n    \"base.en\": \"https://openaipublic.azureedge.net/main/whisper/models/25a8566e1d0c1e2231d1c762132cd20e0f96a85d16145c3a00adf5d1ac670ead/base.en.pt\",\n    \"base\": \"https://openaipublic.azureedge.net/main/whisper/models/ed3a0b6b1c0edf879ad9b11b1af5a0e6ab5db9205f891f668f8b0e6c6326e34e/base.pt\",\n    \"small.en\": \"https://o"
        },
        {
            "comment": "This code defines URLs for different Whisper model versions and languages to download the models.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/__init__.py\":21-27",
            "content": "penaipublic.azureedge.net/main/whisper/models/f953ad0fd29cacd07d5a9eda5624af0f6bcf2258be67c92b79389873d91e0872/small.en.pt\",\n    \"small\": \"https://openaipublic.azureedge.net/main/whisper/models/9ecf779972d90ba49c06d968637d720dd632c55bbf19d441fb42bf17a411e794/small.pt\",\n    \"medium.en\": \"https://openaipublic.azureedge.net/main/whisper/models/d7440d1dc186f76616474e0ff0b3b6b879abc9d1a4926b7adfa41db2d497ab4f/medium.en.pt\",\n    \"medium\": \"https://openaipublic.azureedge.net/main/whisper/models/345ae4da62f9b3d59415adc60127b97c714f32e89e936602e85993674d08dcb1/medium.pt\",\n    \"large-v1\": \"https://openaipublic.azureedge.net/main/whisper/models/e4b87e7e0bf463eb8e6956e646f1e277e901512310def2c24bf0e11bd3c28e9a/large-v1.pt\",\n    \"large-v2\": \"https://openaipublic.azureedge.net/main/whisper/models/81f7c96c852ee8fc832187b0132e569d6c3065a3252ed18e56effd0b6a73e524/large-v2.pt\",\n    \"large-v3\": \"https://openaipublic.azureedge.net/main/whisper/models/e5b1a55b89c1367dacf97e3e19bfd829a01529dbfdeefa8caeb59b3f1b81dadb/large-v3.pt\","
        },
        {
            "comment": "Storage location: \"whisper/__init__.py\":28-43\nCode:\n```python\nalignment_heads = {\n    # ...\n}\n```\nComment for code:\nMaps model name to a base85-encoded boolean array representing cross-attention heads highly correlated to word-level timing in Whisper models.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/__init__.py\":28-43",
            "content": "    \"large\": \"https://openaipublic.azureedge.net/main/whisper/models/e5b1a55b89c1367dacf97e3e19bfd829a01529dbfdeefa8caeb59b3f1b81dadb/large-v3.pt\",\n}\n# base85-encoded (n_layers, n_heads) boolean arrays indicating the cross-attention heads that are\n# highly correlated to the word-level timing, i.e. the alignment between audio and text tokens.\n_ALIGNMENT_HEADS = {\n    \"tiny.en\": b\"ABzY8J1N>@0{>%R00Bk>$p{7v037`oCl~+#00\",\n    \"tiny\": b\"ABzY8bu8Lr0{>%RKn9Fp%m@SkK7Kt=7ytkO\",\n    \"base.en\": b\"ABzY8;40c<0{>%RzzG;p*o+Vo09|#PsxSZm00\",\n    \"base\": b\"ABzY8KQ!870{>%RzyTQH3`Q^yNP!>##QT-<FaQ7m\",\n    \"small.en\": b\"ABzY8>?_)10{>%RpeA61k&I|OI3I$65C{;;pbCHh0B{qLQ;+}v00\",\n    \"small\": b\"ABzY8DmU6=0{>%Rpa?J`kvJ6qF(V^F86#Xh7JUGMK}P<N0000\",\n    \"medium.en\": b\"ABzY8usPae0{>%R7<zz_OvQ{)4kMa0BMw6u5rT}kRKX;$NfYBv00*Hl@qhsU00\",\n    \"medium\": b\"ABzY8B0Jh+0{>%R7}kK1fFL7w6%<-Pf*t^=N)Qr&0RR9\",\n    \"large-v1\": b\"ABzY8r9j$a0{>%R7#4sLmoOs{s)o3~84-RPdcFk!JR<kSfC2yj\",\n    \"large-v2\": b\"ABzY8zd+h!0{>%R7=D0pU<_bnWW*tkYAhobTNnu$jnkEkXqp)j;w1Tzk)UH3X%SZd&fFZ2fC2yj\","
        },
        {
            "comment": "This function downloads a model from the specified URL and saves it either in memory or to disk based on the `in_memory` argument. It also performs an integrity check using SHA256 hash to ensure the downloaded file is correct before returning it.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/__init__.py\":44-68",
            "content": "    \"large-v3\": b\"ABzY8gWO1E0{>%R7(9S+Kn!D~%ngiGaR?*L!iJG9p-nab0JQ=-{D1-g00\",\n    \"large\": b\"ABzY8gWO1E0{>%R7(9S+Kn!D~%ngiGaR?*L!iJG9p-nab0JQ=-{D1-g00\",\n}\ndef _download(url: str, root: str, in_memory: bool) -> Union[bytes, str]:\n    os.makedirs(root, exist_ok=True)\n    expected_sha256 = url.split(\"/\")[-2]\n    download_target = os.path.join(root, os.path.basename(url))\n    if os.path.exists(download_target) and not os.path.isfile(download_target):\n        raise RuntimeError(f\"{download_target} exists and is not a regular file\")\n    if os.path.isfile(download_target):\n        with open(download_target, \"rb\") as f:\n            model_bytes = f.read()\n        if hashlib.sha256(model_bytes).hexdigest() == expected_sha256:\n            return model_bytes if in_memory else download_target\n        else:\n            warnings.warn(\n                f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\"\n            )\n    with urllib.request.urlopen(url) as source, open(download_target, \"wb\") as output:"
        },
        {
            "comment": "This code is a part of the Whisper library, which provides speech recognition capabilities. The function load_model() loads an ASR model given its name, device (optional), download root path (optional) and whether to load it in memory or not. It first checks if the SHA256 checksum matches for the model file, then loads it either into memory or writes to disk.\nThe available_models() function returns a list of available model names.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/__init__.py\":69-105",
            "content": "        with tqdm(\n            total=int(source.info().get(\"Content-Length\")),\n            ncols=80,\n            unit=\"iB\",\n            unit_scale=True,\n            unit_divisor=1024,\n        ) as loop:\n            while True:\n                buffer = source.read(8192)\n                if not buffer:\n                    break\n                output.write(buffer)\n                loop.update(len(buffer))\n    model_bytes = open(download_target, \"rb\").read()\n    if hashlib.sha256(model_bytes).hexdigest() != expected_sha256:\n        raise RuntimeError(\n            \"Model has been downloaded but the SHA256 checksum does not not match. Please retry loading the model.\"\n        )\n    return model_bytes if in_memory else download_target\ndef available_models() -> List[str]:\n    \"\"\"Returns the names of available models\"\"\"\n    return list(_MODELS.keys())\ndef load_model(\n    name: str,\n    device: Optional[Union[str, torch.device]] = None,\n    download_root: str = None,\n    in_memory: bool = False,\n) -> Whisper:\n    \"\"\"\n    Load a Whisper ASR model"
        },
        {
            "comment": "This function takes the model name or a path to a checkpoint, device, download root, and in_memory as parameters. It creates a Whisper ASR model instance and returns it. If no device is specified, it defaults to CUDA if available, otherwise CPU. If no download_root is given, it uses the default path. If the name matches an official model, it downloads the checkpoint file to the specified location. It also keeps track of the alignment_heads for the specific model.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/__init__.py\":107-134",
            "content": "    Parameters\n    ----------\n    name : str\n        one of the official model names listed by `whisper.available_models()`, or\n        path to a model checkpoint containing the model dimensions and the model state_dict.\n    device : Union[str, torch.device]\n        the PyTorch device to put the model into\n    download_root: str\n        path to download the model files; by default, it uses \"~/.cache/whisper\"\n    in_memory: bool\n        whether to preload the model weights into host memory\n    Returns\n    -------\n    model : Whisper\n        The Whisper ASR model instance\n    \"\"\"\n    if device is None:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    if download_root is None:\n        default = os.path.join(os.path.expanduser(\"~\"), \".cache\")\n        download_root = os.path.join(os.getenv(\"XDG_CACHE_HOME\", default), \"whisper\")\n    if name in _MODELS:\n        checkpoint_file = _download(_MODELS[name], download_root, in_memory)\n        alignment_heads = _ALIGNMENT_HEADS[name]\n    elif os.path.isfile(name):"
        },
        {
            "comment": "This code loads a pre-trained Whisper model from a file or in-memory binary data and returns the model. If the specified model name is not found, it raises an error with available models as a reference. The function takes into account the device to which the model will be transferred for computation.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/__init__.py\":135-155",
            "content": "        checkpoint_file = open(name, \"rb\").read() if in_memory else name\n        alignment_heads = None\n    else:\n        raise RuntimeError(\n            f\"Model {name} not found; available models = {available_models()}\"\n        )\n    with (\n        io.BytesIO(checkpoint_file) if in_memory else open(checkpoint_file, \"rb\")\n    ) as fp:\n        checkpoint = torch.load(fp, map_location=device)\n    del checkpoint_file\n    dims = ModelDimensions(**checkpoint[\"dims\"])\n    model = Whisper(dims)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    if alignment_heads is not None:\n        model.set_alignment_heads(alignment_heads)\n    return model.to(device)"
        }
    ]
}