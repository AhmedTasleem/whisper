{
    "summary": "Both comments describe code that preprocesses audio data into a Tensor or Torch tensor format, applies windows and performs STFT, computes mel spectrograms, and optionally moves the tensor to a specific device.",
    "details": [
        {
            "comment": "This code defines constants for audio hyperparameters and a function to load an audio file. It also imports necessary libraries and defines some helper functions.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/audio.py\":0-37",
            "content": "import os\nfrom functools import lru_cache\nfrom subprocess import CalledProcessError, run\nfrom typing import Optional, Union\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom .utils import exact_div\n# hard-coded audio hyperparameters\nSAMPLE_RATE = 16000\nN_FFT = 400\nHOP_LENGTH = 160\nCHUNK_LENGTH = 30\nN_SAMPLES = CHUNK_LENGTH * SAMPLE_RATE  # 480000 samples in a 30-second chunk\nN_FRAMES = exact_div(N_SAMPLES, HOP_LENGTH)  # 3000 frames in a mel spectrogram input\nN_SAMPLES_PER_TOKEN = HOP_LENGTH * 2  # the initial convolutions has stride 2\nFRAMES_PER_SECOND = exact_div(SAMPLE_RATE, HOP_LENGTH)  # 10ms per audio frame\nTOKENS_PER_SECOND = exact_div(SAMPLE_RATE, N_SAMPLES_PER_TOKEN)  # 20ms per audio token\ndef load_audio(file: str, sr: int = SAMPLE_RATE):\n    \"\"\"\n    Open an audio file and read as mono waveform, resampling as necessary\n    Parameters\n    ----------\n    file: str\n        The audio file to open\n    sr: int\n        The sample rate to resample the audio if necessary\n    Returns\n    -------"
        },
        {
            "comment": "This code reads an audio file, decodes it while downmixing and resampling if necessary, converts the audio waveform to a NumPy array in float32 dtype, pads or trims the array to N_SAMPLES (expected by the encoder), and returns the processed audio.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/audio.py\":38-71",
            "content": "    A NumPy array containing the audio waveform, in float32 dtype.\n    \"\"\"\n    # This launches a subprocess to decode audio while down-mixing\n    # and resampling as necessary.  Requires the ffmpeg CLI in PATH.\n    # fmt: off\n    cmd = [\n        \"ffmpeg\",\n        \"-nostdin\",\n        \"-threads\", \"0\",\n        \"-i\", file,\n        \"-f\", \"s16le\",\n        \"-ac\", \"1\",\n        \"-acodec\", \"pcm_s16le\",\n        \"-ar\", str(sr),\n        \"-\"\n    ]\n    # fmt: on\n    try:\n        out = run(cmd, capture_output=True, check=True).stdout\n    except CalledProcessError as e:\n        raise RuntimeError(f\"Failed to load audio: {e.stderr.decode()}\") from e\n    return np.frombuffer(out, np.int16).flatten().astype(np.float32) / 32768.0\ndef pad_or_trim(array, length: int = N_SAMPLES, *, axis: int = -1):\n    \"\"\"\n    Pad or trim the audio array to N_SAMPLES, as expected by the encoder.\n    \"\"\"\n    if torch.is_tensor(array):\n        if array.shape[axis] > length:\n            array = array.index_select(\n                dim=axis, index=torch.arange(length, device=array.device)"
        },
        {
            "comment": "This code defines a function that takes an array and a specific axis, then adjusts the shape of the array to match the desired length. If the array's size along the specified axis is less than the desired length, it pads the array with zeros. If the array's size along the specified axis is greater than the desired length, it trims the array to the specified length. The code also includes a function mel_filters that loads pre-defined Mel filterbank matrices for projecting Short-Time Fourier Transform (STFT) into a Mel spectrogram. This allows decoupling from librosa dependency and uses previously saved data for faster loading.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/audio.py\":72-102",
            "content": "            )\n        if array.shape[axis] < length:\n            pad_widths = [(0, 0)] * array.ndim\n            pad_widths[axis] = (0, length - array.shape[axis])\n            array = F.pad(array, [pad for sizes in pad_widths[::-1] for pad in sizes])\n    else:\n        if array.shape[axis] > length:\n            array = array.take(indices=range(length), axis=axis)\n        if array.shape[axis] < length:\n            pad_widths = [(0, 0)] * array.ndim\n            pad_widths[axis] = (0, length - array.shape[axis])\n            array = np.pad(array, pad_widths)\n    return array\n@lru_cache(maxsize=None)\ndef mel_filters(device, n_mels: int) -> torch.Tensor:\n    \"\"\"\n    load the mel filterbank matrix for projecting STFT into a Mel spectrogram.\n    Allows decoupling librosa dependency; saved using:\n        np.savez_compressed(\n            \"mel_filters.npz\",\n            mel_80=librosa.filters.mel(sr=16000, n_fft=400, n_mels=80),\n            mel_128=librosa.filters.mel(sr=16000, n_fft=400, n_mels=128),\n        )\n    \"\"\"\n    assert n_mels in {80, 128}, f\"Unsupported n_mels: {n_mels}\""
        },
        {
            "comment": "This function computes the log-Mel spectrogram of an audio input. It takes in either a file path, NumPy array, or Tensor containing audio waveform in 16 kHz. The function requires a specific number of Mel frequency filters (only 80 supported), and allows for padding of zero samples to the right. If a device is specified, it moves the audio tensor to that device before applying STFT. It returns a Tensor containing the Mel spectrogram.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/audio.py\":104-137",
            "content": "    filters_path = os.path.join(os.path.dirname(__file__), \"assets\", \"mel_filters.npz\")\n    with np.load(filters_path, allow_pickle=False) as f:\n        return torch.from_numpy(f[f\"mel_{n_mels}\"]).to(device)\ndef log_mel_spectrogram(\n    audio: Union[str, np.ndarray, torch.Tensor],\n    n_mels: int = 80,\n    padding: int = 0,\n    device: Optional[Union[str, torch.device]] = None,\n):\n    \"\"\"\n    Compute the log-Mel spectrogram of\n    Parameters\n    ----------\n    audio: Union[str, np.ndarray, torch.Tensor], shape = (*)\n        The path to audio or either a NumPy array or Tensor containing the audio waveform in 16 kHz\n    n_mels: int\n        The number of Mel-frequency filters, only 80 is supported\n    padding: int\n        Number of zero samples to pad to the right\n    device: Optional[Union[str, torch.device]]\n        If given, the audio tensor is moved to this device before STFT\n    Returns\n    -------\n    torch.Tensor, shape = (80, n_frames)\n        A Tensor that contains the Mel spectrogram\n    \"\"\"\n    if not torch.is_tensor(audio):"
        },
        {
            "comment": "This code loads audio, converts it to a torch tensor, optionally moves the tensor to a specific device, pads the audio if necessary, applies a Hann window function, performs short-time Fourier transform (STFT), computes mel spectrograms, clamps and logs the spectrogram values.",
            "location": "\"/media/root/Toshiba XG3/works/whisper/docs/src/whisper/audio.py\":138-156",
            "content": "        if isinstance(audio, str):\n            audio = load_audio(audio)\n        audio = torch.from_numpy(audio)\n    if device is not None:\n        audio = audio.to(device)\n    if padding > 0:\n        audio = F.pad(audio, (0, padding))\n    window = torch.hann_window(N_FFT).to(audio.device)\n    stft = torch.stft(audio, N_FFT, HOP_LENGTH, window=window, return_complex=True)\n    magnitudes = stft[..., :-1].abs() ** 2\n    filters = mel_filters(audio.device, n_mels)\n    mel_spec = filters @ magnitudes\n    log_spec = torch.clamp(mel_spec, min=1e-10).log10()\n    log_spec = torch.maximum(log_spec, log_spec.max() - 8.0)\n    log_spec = (log_spec + 4.0) / 4.0\n    return log_spec"
        }
    ]
}